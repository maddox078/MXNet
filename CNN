using System;
using System.Collections.Generic;
using System.Diagnostics;
using System.Globalization;
using System.Linq;
using System.Security.Cryptography;
using System.Security.Cryptography.X509Certificates;
using System.Text;
using System.Threading.Tasks;
using System.Windows.Forms.VisualStyles;
using System.Xml.Serialization;

namespace MaddoxNET
{
    public class CNN
    {
        public ANN_Perf NeuralNetwork;
        public int ImageDimensions = 0;
        public List<List<List<List<double>>>> Filters = new List<List<List<List<double>>>>();
        public List<List<List<List<double>>>> PrevDeltas = new List<List<List<List<double>>>>();
        public List<List<List<List<double>>>> FeatureMaps = new List<List<List<List<double>>>>();
        public List<List<List<List<double>>>> Errors = new List<List<List<List<double>>>>();
        public double ReLUConst = 0.2;
        public List<int> PoolingSchedule = new List<int>();
        public List<int> StrideSchedule = new List<int>();

        public CNN(List<int> LayerCounts,List<List<List<List<double>>>> FilterList,List<int> ActivationIDs,List<int> PoolingSchedule, List<int> StrideSchedule,int ImageDim, double LearningRate,double MomentumFactor)
        {
            List<int> TempList = new List<int>();
            List<int> TempList2 = new List<int>();
            List<List<double>> PrimaryFilter = new List<List<double>>();
            int X = 0;
            double TempVal = ImageDim;

            this.ImageDimensions = ImageDim;

            this.NeuralNetwork = new ANN_Perf(LayerCounts, ActivationIDs, 0, LearningRate, MomentumFactor);

            this.Filters = FilterList;
            
            this.PoolingSchedule = PoolingSchedule;
            this.StrideSchedule = StrideSchedule;
            InitializeNetwork();
        }

        public void NormalizeFilters(int NormalizationMethodID)
        {
            int X = 0;
            int Y = 0;
            List<double> TempList = new List<double>();

            while(X < this.Filters.Count)
            {
                Y = 0;
                while(Y < this.Filters[X].Count)
                {
                    TempList = this.Flatten2DVector(this.Filters[X][Y]);
                    TempList = this.NeuralNetwork.NormalizeDataSet(TempList, NormalizationMethodID);

                    this.Filters[X][Y] = this.ExpandVector(TempList);

                    Y++;
                }

                X++;
            }
        }

        public void InitializeNetwork()
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            int ZZ = 0;
            Random Rnd = new Random(System.DateTime.Now.Millisecond);
            List<List<List<double>>> TempList3 = new List<List<List<double>>>();
            List<List<double>> TempErrors = new List<List<double>>();
            List<List<double>> TempWeights = new List<List<double>>();
            List<List<double>> TempFeatures = new List<List<double>>();
            List<double> TempList = new List<double>();
            List<List<double>> TempList2 = new List<List<double>>();

            this.Errors = new List<List<List<List<double>>>>();
            this.PrevDeltas = new List<List<List<List<double>>>>();

            //Filters
            while(X < this.FeatureMaps.Count)
            {
                TempList3 = new List<List<List<double>>>();
                Y = 0;
                while(Y < this.FeatureMaps[X].Count)
                {
                    TempList2 = new List<List<double>>();
                    Z = 0;

                    while(Z < FeatureMaps[X][Y].Count)
                    {
                        TempList = new List<double>();
                        ZZ = 0;
                        while(ZZ < FeatureMaps[X][Y][Z].Count)
                        {
                            TempList.Add(0);
                            //this.PrevDeltas.Add(0);

                            ZZ++;
                        }

                        TempList2.Add(TempList);

                        Z++;
                    }

                    TempList3.Add(TempList2);

                    Y++;
                }

                this.Errors.Add(TempList3);
                this.PrevDeltas.Add(TempList3);

                X++;
            }
        }

        public void FeedForward(List<List<double>> Inputs,bool PoolFeatures)
        {
            List<List<List<double>>> FinalInputs = new List<List<List<double>>>();
            List<List<List<double>>> SubInputs = new List<List<List<double>>>();
            int X = 0;
            int Y = 0;

            this.FeatureMaps = new List<List<List<List<double>>>>();

            SubInputs.Add(Inputs);

            while(X < this.Filters.Count)
            {
                SubInputs = this.Convolve(SubInputs, this.Filters[X], this.StrideSchedule[X]);              
                
                if(PoolFeatures)
                {
                    SubInputs = this.PoolLayer(SubInputs, this.PoolingSchedule[X], false);
                }
                
                SubInputs = this.ActivateConvolutions(SubInputs,2);

                this.FeatureMaps.Add((SubInputs));

                X++;
            }

            this.NeuralNetwork.ForwardPropagate(this.Flatten3DVector(this.FeatureMaps[this.FeatureMaps.Count - 1]),9);
         }

        public List<List<double>> ExpandVector(List<double> Input)
        {
            List<List<double>> FinalOutput = new List<List<double>>();
            List<List<double>> Output = new List<List<double>>();
            List<double> SubOutput = new List<double>();
            int X = 0;
            int Y = 0;
            int Z = 0;

            //This needs to make an x y grid of rgbs
            while (Z < Input.Count)
            {
                X = 0;

                SubOutput.Add(Input[Z]);

                if ((Z + 1) % (int)(Math.Sqrt(Input.Count)) == 0 && Z != 0)
                {
                    FinalOutput.Add(SubOutput);
                    SubOutput = new List<double>();
                }

                Z++;
            }

            return FinalOutput;
        }
        public void BackPropagate(List<List<double>> Inputs,List<double> Outputs,bool PoolActivations,bool TrainWeights)
        {
            int X = this.Filters.Count - 1;
            int Y = 0;
            int Z = 0;
            int ZZ = 0;
            int ZZZ = 0;
            int ZZZZ = 0;
            int A = 0;
            int B = 0;
            int C = 0;
            int D = 0;
            int E = 0;
            List<double> LocalActivations = new List<double>();
            List<double> PreviousActivations = new List<double>();
            List<double> PreviousErrors = new List<double>();
            List<double> LocalErrors = new List<double>();
            List<double> PreviousWeights = new List<double>();
            List<double> Filters = new List<double>();
            List<double> TempList = new List<double>();
            List<List<double>> TempList2 = new List<List<double>>();
            List<List<List<List<double>>>> Errors = new List<List<List<List<double>>>>();
            List<List<List<double>>> SubErrors = new List<List<List<double>>>();
            List<List<double>> SubSubErrors = new List<List<double>>();
            List<double> SubSubSubErrors = new List<double>();
            double Delta = 0;
            double NewDelta = 0;

            double TempVal1 = 0;
            double TempVal2 = 0;
            double TempVal3 = 0;

            //this.Errors = new List<List<List<List<double>>>>();

            this.FeedForward(Inputs,PoolActivations);

            LocalActivations = this.Flatten2DVector(Inputs);

            InitializeNetwork();

            //Normal: 2x45x45
            this.NeuralNetwork.BackPropagate(this.Flatten3DVector(this.FeatureMaps[this.FeatureMaps.Count - 1]), Outputs, 9, TrainWeights);

            E = this.Filters.Count - 1;

            while(E > 0)
            {
                SubErrors = new List<List<List<double>>>();
                X = 0;
                while (X < this.FeatureMaps[E].Count)
                {
                    SubSubErrors = new List<List<double>>();
                    Y = 0;
                    while (Y < this.FeatureMaps[E][X].Count)
                    {
                        SubSubSubErrors = new List<double>();
                        Z = 0;
                        while (Z < this.FeatureMaps[E][X][Y].Count)
                        {
                            Delta = 0;
                            ZZ = 0;

                            if(E == this.Filters.Count - 1)
                            {
                                while (ZZ < this.NeuralNetwork.Activations[0].Count)
                                {
                                    D = (Y * this.FeatureMaps[this.FeatureMaps.Count - 1][X].Count) + Z;
                                    Delta += (this.NeuralNetwork.Errors[0][ZZ] * this.NeuralNetwork.ActivationFunctionDerivative(this.NeuralNetwork.Activations[0][ZZ], 3) * this.NeuralNetwork.Weights[0][ZZ][D]);

                                    ZZ++;
                                }

                                Delta /= ZZ;
                            }
                            else
                            {
                                //Feature Maps
                                while(ZZ < this.FeatureMaps[E+1].Count)
                                {
                                    //Map Y
                                    ZZZ = 0;
                                    while(ZZZ < this.FeatureMaps[E + 1][ZZ].Count)
                                    {
                                        //Map X
                                        ZZZZ = 0;
                                        while(ZZZZ < this.FeatureMaps[E + 1][ZZ][ZZZ].Count)
                                        {
                                            A = (int)(ZZ / ((int)(this.FeatureMaps[E].Count / this.Filters[E].Count) * this.Filters[E+1].Count));
                                            B = (int)(Y / (this.FeatureMaps[E+1][ZZ].Count * this.PoolingSchedule[E]));
                                            C = (int)(Z / (this.FeatureMaps[E+1][ZZ][ZZZ].Count * this.PoolingSchedule[E]));
                                            

                                            //A = (int)(ZZ / this.FeatureMaps[E + 1].Count);
                                            //B = (int)(ZZZ / this.FeatureMaps[E + 1][A].Count);
                                            //C = (int)(ZZZZ / this.FeatureMaps[E + 1][A][B].Count);
                                            TempVal1 = this.Errors[(E+1)][ZZ][ZZZ][ZZZZ];
                                            TempVal2 = this.NeuralNetwork.ActivationFunctionDerivative(this.FeatureMaps[E + 1][ZZ][ZZZ][ZZZZ], 3);
                                            TempVal3 = this.Filters[E][A][B][C];

                                            Delta += (TempVal1 * TempVal2 * TempVal3);

                                            ZZZZ++;
                                        }

                                        ZZZ++;
                                    }

                                    ZZ++;
                                }

                                Delta /= (ZZZZ * ZZZ * ZZ);
                            }


                            //Delta *= Delta;

                            this.Errors[E][X][Y][Z] = Delta;

                            SubSubSubErrors.Add(Delta);

                            A = 0;

                            while (A < this.Filters[E].Count)
                            {
                                B = 0;
                                while (B < this.Filters[E][A].Count)
                                {
                                    C = 0;
                                    while (C < this.Filters[E][A][B].Count)
                                    {
                                        if(E == 0)
                                        {
                                            D = (A * (this.Filters[E][A].Count * this.Filters[E][A][B].Count)) + (B * this.Filters[E][A].Count) + C;
                                            TempVal2 = LocalActivations[D];
                                            TempVal1 = this.NeuralNetwork.ActivationFunctionDerivative(this.FeatureMaps[E][X][Y][Z], 3);

                                            NewDelta = Delta * TempVal1 * TempVal2;
                                        }
                                        else
                                        {
                                            ZZ = (int)(X / this.Filters[E].Count) ;
                                            ZZZ = (int)(Y * this.PoolingSchedule[E]);
                                            ZZZZ = (int)(Z * this.PoolingSchedule[E]);

                                            NewDelta = Delta * this.NeuralNetwork.ActivationFunctionDerivative(this.FeatureMaps[E][X][Y][Z], 3) * this.FeatureMaps[E - 1][ZZ][ZZZ][ZZZZ];
                                        }
                                        

                                        if (TrainWeights)
                                        {
                                            this.Filters[E][A][B][C] = this.Filters[E][A][B][C] - ((this.NeuralNetwork.LearningRate * NewDelta) + (this.NeuralNetwork.Momentum * this.PrevDeltas[E][A][B][C]));
                                        }

                                        //this.PrevDeltas[E][A][B][C] = NewDelta;
                                        this.PrevDeltas[E][A][B][C] = 0;

                                        C++;
                                    }

                                    B++;
                                }

                                A++;
                            }

                            Z++;
                        }


                        SubSubErrors.Add(SubSubSubErrors);

                        Y++;
                    }

                    SubErrors.Add(SubSubErrors);

                    X++;
                }

                //this.Errors.Add(SubErrors);

                E--;
            }

            

        }


        public List<List<List<double>>> AvgValues(List<List<List<double>>> Inputs,int Iterations)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;

            while(X < Inputs.Count)
            {
                Y = 0;
                while(Y < Inputs[X].Count)
                {
                    Z = 0;
                    while(Z < Inputs[X][Y].Count)
                    {
                        Inputs[X][Y][Z] /= Iterations;

                        Z++;
                    }

                    Y++;
                }

                X++;
            }

            return Inputs;
        }

        public List<double> GenerateNoiseSample(int Size)
        {
            Random Rnd = new Random(System.DateTime.Now.Millisecond * System.DateTime.Now.Second * System.DateTime.Now.Minute);
            int X = 0;
            List<double> RetVal = new List<double>();

            while (X < Size)
            {
                RetVal.Add(Rnd.NextDouble() % 0.255);

                X++;
            }

            return RetVal;
        }

        public List<List<List<double>>> PoolLayer(List<List<List<double>>> Input,int KernelSize,bool AvgLayer)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            int A = 0;
            int B = 0;
            double MaxVal = 0;
            double AvgVal = 0;
            List<List<double>> RetVal = new List<List<double>>();
            List<double> TempVals = new List<double>();
            List<List<List<double>>> FinalRetVal = new List<List<List<double>>>();

            Z = 0;
            while (Z < Input.Count)
            {
                RetVal = new List<List<double>>();
                X = 0;
                while (X < Input[Z].Count)
                {
                    TempVals = new List<double>();
                    Y = 0;
                    while (Y < Input[Z][X].Count)
                    {
                        AvgVal = 0;
                        MaxVal = Input[Z][X][Y];
                        A = 0;
                        while (A < KernelSize)
                        {
                            B = 0;
                            while (B < KernelSize)
                            {
                                if (A + X < Input[Z][X].Count && B + Y < Input[Z][X].Count)
                                {
                                    AvgVal += Input[Z][X + A][Y + B];

                                    if (Input[Z][X + A][Y + B] > MaxVal)
                                    {
                                        MaxVal = Input[Z][X + A][Y + B];
                                    }
                                }


                                B++;
                            }

                            A++;
                        }

                        AvgVal /= (KernelSize * KernelSize);

                        if (AvgLayer)
                        {
                            TempVals.Add(AvgVal);
                        }
                        else
                        {
                            TempVals.Add(MaxVal);
                        }

                        Y+=KernelSize;
                    }

                    RetVal.Add(TempVals);

                    X+=KernelSize;
                }

                FinalRetVal.Add(RetVal);

                Z++;
            }

            return FinalRetVal;
        }

        public List<List<List<double>>> ActivateConvolutions(List<List<List<double>>> Input,int ActivationID)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            List<List<List<double>>> Output = Input;

            while(X < Input.Count)
            {
                Y = 0;
                while( Y < Input[X].Count)
                {
                    Z = 0;
                    while(Z < Input[X][Y].Count)
                    {
                        switch(ActivationID)
                        {
                            case 0:
                                Output[X][Y][Z] = Math.Tanh(Input[X][Y][Z]);
                                break;

                            case 1:
                                Output[X][Y][Z] = this.Sigmoid(Input[X][Y][Z]);
                                break;

                            case 2:
                                Output[X][Y][Z] = this.ReLU(Input[X][Y][Z], true);
                                break;
                        }
                        

                        Z++;
                    }

                    Y++;

                }

                X++;
            }

            return Output;
        }

        public void BackpropagateError(List<List<List<double>>> Activation,int FilterID)
        {
            
        }

        public List<List<List<double>>> Convolve(List<List<List<double>>> Input, List<List<List<double>>> Input2, int Stride)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            int ZZ = 0;
            int A = 0;
            int B = 0;
            int C = 0;
            int D = 0;
            double TempVal = 0;            
            List<double> TempList = new List<double>();
            List<List<double>> TempList2 = new List<List<double>>();
            List<List<List<double>>> TempList3 = new List<List<List<double>>>();

            C = 0;
            while (C < 3)
            {                
                //Feature Maps
                while (X < Input.Count)
                {
                    //Filters
                    Y = 0;
                    while (Y < Input2.Count)
                    {
                        //Map Y
                        TempList2 = new List<List<double>>();
                        Z = 0;
                        while (Z < Input[X].Count)
                        {
                            //Map X
                            TempList = new List<double>();
                            ZZ = 0;
                            while (ZZ < Input[X][Z].Count)
                            {
                                TempVal = 0;
                                A = 0;
                                while (A < Input2[Y].Count)
                                {
                                    B = 0;
                                    while (B < Input2[Y][A].Count)
                                    {
                                        if (Z + A < Input[X].Count && ZZ + B < Input[X][Z].Count)
                                        {
                                            if(C == 0)
                                            {
                                                TempVal += (Input[X][Z + A][ZZ + B] * Input2[Y][A][B]);
                                            }
                                            else
                                            {
                                                TempVal += (TempList3[X][Z + A][ZZ + B] * Input2[Y][A][B]);
                                            }
                                            
                                        }

                                        B++;
                                    }

                                    A++;
                                }

                                //TempVal /= (A * B);

                                TempList.Add(TempVal);

                                ZZ += Stride;
                            }

                            TempList2.Add(TempList);


                            Z += Stride;
                        }

                        if (C == 0)
                        {
                            TempList3.Add(this.ExpandVector(this.NeuralNetwork.NormalizeDataSet(this.Flatten2DVector(TempList2), 4)));
                        }
                        else
                        {
                            D = 0;
                            while(D < TempList3.Count)
                            {
                                TempList3[D] = this.ExpandVector(this.NeuralNetwork.NormalizeDataSet(this.Flatten2DVector(TempList3[D]), 4));

                                D++;
                            }
                        }
                        

                        Y++;
                    }

                    X++;
                }

                C++;
            }

            return TempList3;
        }

        public List<List<List<double>>> PoolActivations(List<List<List<double>>> Activations)
        {
            List<List<List<double>>> RetVal = new List<List<List<double>>>();
            List<List<double>> TempList2 = new List<List<double>>();
            List<double> TempList = new List<double>();
            int X = 0;
            int Y = 0;
            int Z = 0;
            int A = 0;
            int B = 0;
            int C = 0;
            double MaxVal = 0;

            while(X < Activations[0].Count)
            {
                TempList = new List<double>();
                Y = 0;
                while( Y < Activations[0][0].Count)
                {
                    MaxVal = Activations[0][X][Y];
                    Z = 0;
                    while(Z < Activations.Count)
                    {
                        if (Activations[Z][X][Y] > MaxVal)
                        {
                            MaxVal = Activations[Z][X][Y];
                        }

                        Z++;
                    }

                    TempList.Add(MaxVal);

                    Y++;
                }

                TempList2.Add(TempList);

                X++;
            }

            RetVal.Add(TempList2);

            return RetVal;
        }

        
        public List<double> ConcatVectors(List<double> Input1,List<double> Input2)
        {
            List<double> RetVal = new List<double>();
            int X = 0;

            while(X < Input1.Count)
            {
                RetVal.Add(Input1[X]);

                X++;
            }

            X = 0;
            while(X < Input2.Count)
            {
                RetVal.Add(Input2[X]);

                X++;
            }

            return RetVal;
        }

        public List<double> Flatten3DVector(List<List<List<double>>> Input)
        {
            //Normal: 2x63x63
            int X = 0;
            int Y = 0;
            int Z = 0;
            List<double> RetVal = new List<double>();

            while(X < Input.Count)
            {
                Y = 0;
                while (Y < Input[X].Count)
                {
                    Z = 0;
                    while(Z < Input[X][Y].Count)
                    {
                        RetVal.Add(Input[X][Y][Z]);

                        Z++;
                    }

                    Y++;
                }

                X++;
            }

            return RetVal;
        }

        public List<double> Flatten2DVector(List<List<double>> Input)
        {
            int X = 0;
            int Y = 0;
            List<double> Output = new List<double>();

            while(X < Input.Count)
            {
                Y = 0;
                while(Y < Input[X].Count)
                {
                    Output.Add(Input[X][Y]);

                    Y++;
                }

                X++;
            }

            return Output;
        }

        public Bitmap ArrayToBMP(List<List<double>> Input)
        {
            int ImageDim = (int)(Math.Round(Math.Sqrt(Input.Count), MidpointRounding.AwayFromZero));
            Bitmap RetVal = new Bitmap(ImageDim, ImageDim);
            int X = 0;
            int Y = 0;
            int RGB = 0;
            int RVal = 0;
            int GVal = 0;
            int BVal = 0;
            int NewX = 0;
            int NewY = 0;
            double TempVal = 0;
            double MinVal = Input[0][0];

            X = 0;
            while (X < Input.Count)
            {
                NewX = X % ImageDim;
                NewY = (int)(X / ImageDim);
                RVal = Math.Max(0, Math.Min(255, (int)Math.Abs(Input[X][0])));
                GVal = Math.Max(0, Math.Min(255, (int)Math.Abs(Input[X][1])));
                BVal = Math.Max(0, Math.Min(255, (int)Math.Abs(Input[X][2])));

                RGB = 255 - RVal;


                if (NewX < RetVal.Width && NewY < RetVal.Height)
                {
                    //RetVal.SetPixel(NewX, NewY, Color.FromArgb(RGB, RGB, RGB));

                    RetVal.SetPixel(NewX, NewY, Color.FromArgb(RGB, RGB, RGB));
                }


                if (Input[X][0] < MinVal)
                {
                    MinVal = Input[X][0];
                }

                X += 1;
            }


            //Debug.Print(MinVal.ToString() + " - " + this.NeuralNetwork.MeanSquaredError.ToString());

            return RetVal;
        }

        public List<List<double>> BMPToArrayColor(Bitmap Input)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            List<double> TempRow = new List<double>();
            List<List<double>> TempRow2 = new List<List<double>>();
            List<List<double>> RetVal = new List<List<double>>();

            Input = new Bitmap(Input, this.ImageDimensions, this.ImageDimensions);

            X = 0;
            TempRow2 = new List<List<double>>();
            while (X < Input.Height)
            {
                Y = 0;
                TempRow = new List<double>();
                while (Y < Input.Width)
                {
                    //TempRow.Add(((((Input.GetPixel(Y, X).R + Input.GetPixel(Y, X).G + Input.GetPixel(Y, X).B) / 3) * 0.001)));
                    TempRow.Add(Input.GetPixel(Y, X).R * 0.001);
                    TempRow.Add(Input.GetPixel(Y, X).G * 0.001);
                    TempRow.Add(Input.GetPixel(Y, X).B * 0.001);


                    Y++;
                }

                RetVal.Add(TempRow);

                X++;
            }

            return RetVal;
        }


        public List<List<List<double>>> BMPToArray(Bitmap Input)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            List<double> TempRow = new List<double>();
            List<List<double>> TempRow2 = new List<List<double>>();
            List<List<double>> RetVal = new List<List<double>>();
            List<List<List<double>>> FinalRetVal = new List<List<List<double>>>();

            Input = new Bitmap(Input, this.ImageDimensions, this.ImageDimensions);

            X = 0;
            TempRow2 = new List<List<double>>();
            while (X < Input.Height)
            {
                Y = 0;
                TempRow = new List<double>();
                while (Y < Input.Width)
                {
                    TempRow.Add(((((Input.GetPixel(Y, X).R + Input.GetPixel(Y, X).G + Input.GetPixel(Y, X).B) / 3) * 0.001)));

                    Y++;
                }

                RetVal.Add(TempRow);

                X++;
            }

            FinalRetVal.Add(RetVal);

            return FinalRetVal;
        }

        public double ReLU(double Input,bool LeakyReLU)
        {
            double TempVal = 0;

            if(LeakyReLU)
            {                
                if (Input >= 0)
                {
                    TempVal = Input;
                }
                else
                {
                    TempVal = Input * this.NeuralNetwork.ReLUConst;
                }
            }
            else
            {
                if (Input >= 0)
                {
                    TempVal = Input;
                }
                else
                {
                    TempVal = 0;
                }
            }
            

            return TempVal;
        }

        public double Sigmoid(double Input)
        {
            double TempVal = 0;

            TempVal = 1 / (1 + Math.Pow(Math.E, -1 * Input));

            return TempVal;
        }
    }
}
