using System;
using System.Collections.Generic;
using System.Diagnostics;
using System.Globalization;
using System.IO.Packaging;
using System.Linq;
using System.Linq.Expressions;
using System.Reflection;
using System.Security.Cryptography;
using System.Security.Cryptography.X509Certificates;
using System.Security.Cryptography.Xml;
using System.Text;
using System.Threading.Tasks;
using System.Windows.Forms.VisualStyles;
using System.Xml.Serialization;

namespace MaddoxNET
{
    public class CNN
    {
        public ANN_Perf NeuralNetwork;
        public int ImageDimensions = 0;
        public List<List<List<List<double>>>> Filters = new List<List<List<List<double>>>>();
        public List<List<List<List<double>>>> CurrentDeltas = new List<List<List<List<double>>>>();
        public List<List<List<List<double>>>> PrevDeltas = new List<List<List<List<double>>>>();
        public List<List<List<List<double>>>> FiltersM = new List<List<List<List<double>>>>();
        public List<List<List<List<double>>>> FiltersV = new List<List<List<List<double>>>>();
        public List<List<List<List<double>>>> FeatureMaps = new List<List<List<List<double>>>>();
        public List<List<List<List<List<double>>>>> MaxFeatureMaps = new List<List<List<List<List<double>>>>>();
        public List<List<List<List<double>>>> PrePoolFeatureMaps = new List<List<List<List<double>>>>();
        public List<List<List<List<double>>>> RawFeatureMaps = new List<List<List<List<double>>>>();
        public List<List<List<List<double>>>> DerivativeFeatureMaps = new List<List<List<List<double>>>>();
        public List<List<List<List<double>>>> Errors = new List<List<List<List<double>>>>();
        public List<List<List<List<double>>>> MaxPoolGradients = new List<List<List<List<double>>>>();
        public List<double> SampleErrors = new List<double>();
        public List<double> SampleWeightDeltas = new List<double>();
        public List<double> SampleActivations = new List<double>();
        public double ReLUConst = 0.01;
        public double LearningRate = 0;
        public List<int> PoolingSchedule = new List<int>();
        public List<int> StrideSchedule = new List<int>();
        public double FilterVariance = 0;
        public double FilterMean = 0;
        public int GlobalIterator = 0;
        public List<int> CNNActivationFunctionIDs = new List<int>();

        public CNN(List<int> LayerCounts,List<List<List<List<double>>>> FilterList,List<int> ActivationIDs, List<int> CNNActivationIDs,List<int> PoolingSchedule, List<int> StrideSchedule,int ImageDim, double LearningRate,double MomentumFactor,int WeightInitializationID=0)
        {
            List<int> TempList = new List<int>();
            List<int> TempList2 = new List<int>();
            List<List<double>> PrimaryFilter = new List<List<double>>();
            int X = 0;
            double TempVal = ImageDim;

            this.ImageDimensions = ImageDim;

            this.NeuralNetwork = new ANN_Perf(LayerCounts, ActivationIDs, 2, LearningRate, MomentumFactor,WeightInitializationID);

            this.Filters = FilterList;

            this.CNNActivationFunctionIDs = CNNActivationIDs;
            this.PoolingSchedule = PoolingSchedule;
            this.StrideSchedule = StrideSchedule;
            InitializeNetwork();
            InitializeMV();
            InitializePooling();
        }

        public void InitializeMV()
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            int ZZ = 0;
            List<double> TempListM = new List<double>();
            List<List<double>> TempList2M = new List<List<double>>();
            List<List<List<double>>> TempList3M = new List<List<List<double>>>();
            List<double> TempListV = new List<double>();
            List<List<double>> TempList2V = new List<List<double>>();
            List<List<List<double>>> TempList3V = new List<List<List<double>>>();

            while (X < this.Filters.Count)
            {
                TempList3M = new List<List<List<double>>>();
                TempList3V = new List<List<List<double>>>();
                Y = 0;
                while(Y < this.Filters[X].Count)
                {
                    TempList2M = new List<List<double>>();
                    TempList2V = new List<List<double>>();
                    Z = 0;
                    while(Z < this.Filters[X][Y].Count)
                    {
                        TempListM = new List<double>();
                        TempListV = new List<double>();
                        ZZ = 0;
                        while(ZZ < this.Filters[X][Y][Z].Count)
                        {
                            TempListM.Add(0);
                            TempListV.Add(0);

                            ZZ++;
                        }

                        TempList2M.Add(TempListM);
                        TempList2V.Add(TempListV);

                        Z++;
                    }

                    TempList3M.Add(TempList2M);
                    TempList3V.Add(TempList2V);

                    Y++;
                }

                this.FiltersM.Add(TempList3M);
                this.FiltersV.Add(TempList3V);

                X++;
            }
        }


        public void ClearGradients()
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            int ZZ = 0;
            List<double> Templist = new List<double>();
            List<List<double>> TempList2 = new List<List<double>>();
            List<List<List<double>>> TempList3 = new List<List<List<double>>>();
            List<List<List<List<double>>>> TempList4 = new List<List<List<List<double>>>>();

            this.CurrentDeltas = new List<List<List<List<double>>>>();

            while (X < this.Filters.Count)
            {
                TempList3 = new List<List<List<double>>>();
                Y = 0;
                while (Y < this.Filters[X].Count)
                {
                    TempList2 = new List<List<double>>();
                    Z = 0;
                    while (Z < this.Filters[X][Y].Count)
                    {
                        Templist = new List<double>();
                        ZZ = 0;
                        while (ZZ < this.Filters[X][Y][Z].Count)
                        {
                            Templist.Add(0);

                            ZZ++;
                        }

                        TempList2.Add(Templist);

                        Z++;
                    }

                    TempList3.Add(TempList2);

                    Y++;
                }

                TempList4.Add(TempList3);

                X++;
            }

            this.CurrentDeltas = TempList4;
        }

        public void InitializeNetwork()
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            int ZZ = 0;
            Random Rnd = new Random(System.Guid.NewGuid().GetHashCode());
            List<List<List<double>>> TempList3 = new List<List<List<double>>>();
            List<List<List<double>>> TempList4 = new List<List<List<double>>>();
            List<List<double>> TempErrors = new List<List<double>>();
            List<List<double>> TempWeights = new List<List<double>>();
            List<List<double>> TempFeatures = new List<List<double>>();
            List<double> TempList = new List<double>();
            List<double> TempList6 = new List<double>();
            List<List<double>> TempList2 = new List<List<double>>();
            List<List<double>> TempList5 = new List<List<double>>();
            bool Flag = false;

            this.Errors = new List<List<List<List<double>>>>();

            if (this.GlobalIterator == 0)
            {
                Flag = true;
                this.PrevDeltas = new List<List<List<List<double>>>>();
                this.CurrentDeltas = new List<List<List<List<double>>>>();
            }

            X = 0;
            //Filters
            while (X < this.FeatureMaps.Count)
            {
                TempList3 = new List<List<List<double>>>();
                //this.MaxFeatureMaps.Add(TempList3);
                Y = 0;
                while(Y < this.FeatureMaps[X].Count)
                {
                    TempList2 = new List<List<double>>();
                    Z = 0;

                    while(Z < FeatureMaps[X][Y].Count)
                    {
                        TempList = new List<double>();
                        ZZ = 0;
                        while(ZZ < FeatureMaps[X][Y][Z].Count)
                        {
                            TempList.Add(0);
                            //this.PrevDeltas.Add(0);

                            ZZ++;
                        }

                        TempList2.Add(TempList);

                        Z++;
                    }

                    TempList3.Add(TempList2);

                    Y++;
                }

                this.Errors.Add(TempList3);
                

                X++;
            }


            if(Flag)
            {
                X = 0;
                while (X < this.Filters.Count)
                {
                    TempList3 = new List<List<List<double>>>();
                    TempList4 = new List<List<List<double>>>();
                    Y = 0;
                    while (Y < this.Filters[X].Count)
                    {
                        TempList2 = new List<List<double>>();
                        TempList5 = new List<List<double>>();
                        Z = 0;
                        while (Z < this.Filters[X][Y].Count)
                        {
                            TempList = new List<double>();
                            TempList6 = new List<double>();
                            ZZ = 0;
                            while (ZZ < this.Filters[X][Y][Z].Count)
                            {
                                TempList.Add(0);
                                TempList6.Add(0);

                                ZZ++;
                            }

                            TempList2.Add(TempList);
                            TempList5.Add(TempList6);

                            Z++;
                        }

                        TempList3.Add(TempList2);
                        TempList4.Add(TempList5);

                        Y++;
                    }

                    this.PrevDeltas.Add(TempList3);
                    this.CurrentDeltas.Add(TempList4);

                    X++;
                }
            }
        }

        public double GetAverageFeatureError(int LayerID)
        {
            double RetVal = 0;
            int X = 0;
            int Y = 0;
            int Z = 0;
            int TotalCount = 0;

            while(Z < this.Errors[LayerID].Count)
            {
                Y = 0;
                while(Y < this.Errors[LayerID][Z].Count)
                {
                    X = 0;
                    while(X < this.Errors[LayerID][Z][Y].Count)
                    {
                        RetVal += this.Errors[LayerID][Z][Y][X];
                        TotalCount++;

                        X++;
                    }

                    Y++;
                }

                Z++;
            }

            return RetVal / TotalCount;
        }

        public double GetAverageFeature(int LayerID)
        {
            double RetVal = 0;
            int X = 0;
            int Y = 0;
            int Z = 0;
            int TotalCount = 0;

            while (Z < this.FeatureMaps[LayerID].Count)
            {
                Y = 0;
                while (Y < this.FeatureMaps[LayerID][Z].Count)
                {
                    X = 0;
                    while (X < this.FeatureMaps[LayerID][Z][Y].Count)
                    {
                        RetVal += this.FeatureMaps[LayerID][Z][Y][X];
                        TotalCount++;

                        X++;
                    }

                    Y++;
                }

                Z++;
            }

            return RetVal / TotalCount;
        }

        public double GetAverageFilter(int LayerID)
        {
            double RetVal = 0;
            int X = 0;
            int Y = 0;
            int Z = 0;
            int TotalCount = 0;

            while (Z < this.Filters[LayerID].Count)
            {
                Y = 0;
                while (Y < this.Filters[LayerID][Z].Count)
                {
                    X = 0;
                    while (X < this.Filters[LayerID][Z][Y].Count)
                    {
                        RetVal += this.Filters[LayerID][Z][Y][X];
                        TotalCount++;

                        X++;
                    }

                    Y++;
                }

                Z++;
            }

            return RetVal / TotalCount;
        }

        public List<List<List<double>>> ReshapeFullyConnectedLayer()
        {
            List<List<List<double>>> Outputs = new List<List<List<double>>>();
            List<double> TempList1 = new List<double>();
            List<List<double>> TempList2 = new List<List<double>>();
            int X = 0;

            while(X < this.NeuralNetwork.Activations[this.NeuralNetwork.Activations.Count - 1].Count)
            {
                if(X > 0 && X % this.ImageDimensions == 0)
                {
                    TempList2.Add(TempList1);
                    TempList1 = new List<double>();
                }

                if(TempList2.Count > 0 && TempList2.Count % this.ImageDimensions == 0)
                {
                    Outputs.Add(TempList2);
                    TempList2 = new List<List<double>>();
                }

                TempList1.Add(this.NeuralNetwork.Activations[this.NeuralNetwork.Activations.Count - 1][X]);

                X++;
            }

            //TempList2.Add(TempList1);
            //Outputs.Add(TempList2);

            return Outputs;
        }

        public void FeedForwardGenerator(List<double> Inputs, bool PoolFeatures, int OutputNormalization = 9, bool NormalizeOutputs = true)
        {
            List<List<List<double>>> FinalInputs = new List<List<List<double>>>();
            List<List<List<double>>> SubInputs = new List<List<List<double>>>();
            List<List<List<double>>> SubInputs2 = new List<List<List<double>>>();
            int X = 0;
            int Y = 0;
            int Z = 0;
            int ZZ = 0;

            this.FeatureMaps = new List<List<List<List<double>>>>();
            this.RawFeatureMaps = new List<List<List<List<double>>>>();
            this.DerivativeFeatureMaps = new List<List<List<List<double>>>>();
            this.PrePoolFeatureMaps = new List<List<List<List<double>>>>();

            this.NeuralNetwork.ForwardPropagate(Inputs, OutputNormalization, NormalizeOutputs);

            SubInputs = ReshapeTensor(this.NeuralNetwork.Activations[this.NeuralNetwork.Activations.Count - 1], this.Filters[0].Count);

            X = 0;
            while (X < this.Filters.Count)
            {
                if (X > 0)
                {
                    SubInputs = new List<List<List<double>>>();
                    SubInputs = this.FeatureMaps[X - 1];
                }

                //I think there's an issue with my understanding of the N-1 with the feature maps and filters

                SubInputs = this.Convolve(SubInputs, this.Filters[X], this.StrideSchedule[X], false);

                this.DerivativeFeatureMaps.Add(this.ActivateDerivativeConvolutions(SubInputs, this.CNNActivationFunctionIDs[X]));

                //this.PrePoolFeatureMaps.Add(SubInputs);

                this.RawFeatureMaps.Add(SubInputs);

                if (X >= 0)
                {
                    SubInputs = this.ActivateConvolutions(this.RawFeatureMaps[X], this.CNNActivationFunctionIDs[X]);
                }

                if (PoolFeatures)
                {
                    //SubInputs = this.PoolLayer(SubInputs, X, this.PoolingSchedule[X], true);
                }


                //this.RawFeatureMaps.Add(SubInputs);
                //this.RawFeatureMaps[X] = this.NormalizeDataSet(this.RawFeatureMaps[X], 3);



                this.FeatureMaps.Add(SubInputs);                

                X++;
            }

            //this.GlobalIterator++;

            
        }

        public void InitializePooling()
        {
            int X = 0;
            int Y = 0;
            int A = 0;
            int B = 0;
            int C = 0;
            List<double> TempList1 = new List<double>();
            List<List<double>> TempList2 = new List<List<double>>();
            List<List<double>> TempMap = new List<List<double>>();
            List<List<List<double>>> TempList3a = new List<List<List<double>>>();
            List<List<List<double>>> TempList3b = new List<List<List<double>>>();
            List<List<List<List<double>>>> TempList4a = new List<List<List<List<double>>>>();
            List<List<List<List<double>>>> TempList4b = new List<List<List<List<double>>>>();
            List<List<List<List<List<double>>>>> TempList5 = new List<List<List<List<List<double>>>>>();
            double Limit = this.ImageDimensions;
            double SubLimit = Limit;
            int LastDim = this.ImageDimensions;

            while(X < this.Filters.Count)
            {
                LastDim = LastDim - this.Filters[X][0][0].Count + 1;
                TempList3a = new List<List<List<double>>>();
                Y = 0;
                while(Y < this.Filters[X].Count)
                {
                    TempMap = this.CreateEmptyMap(LastDim);

                    TempList3a.Add(TempMap);

                    Y++;
                }

                this.MaxPoolGradients.Add(TempList3a);

                X++;
            }

        }

        public void FeedForward(List<List<double>> Inputs,bool PoolFeatures,int OutputNormalization = 9,bool NormalizeOutputs = true)
        {
            List<List<List<List<double>>>> FinalInputs = new List<List<List<List<double>>>>();
            List<List<List<double>>> SubInputs = new List<List<List<double>>>();
            List<List<List<double>>> SubInputs2 = new List<List<List<double>>>();
            List<double> TempList = new List<double>();
            int X = 0;
            int Y = 0;
            int Z = 0;
            int ZZ = 0;

            this.FeatureMaps = new List<List<List<List<double>>>>();
            this.RawFeatureMaps = new List<List<List<List<double>>>>();
            this.DerivativeFeatureMaps = new List<List<List<List<double>>>>();
            this.PrePoolFeatureMaps = new List<List<List<List<double>>>>();

            SubInputs.Add(Inputs);

            X = 0;
            while (X < this.Filters.Count)
            {
                if(X > 0)
                {
                    SubInputs = new List<List<List<double>>>();
                    SubInputs = this.FeatureMaps[X - 1];
                }
                
                //I think there's an issue with my understanding of the N-1 with the feature maps and filters


                SubInputs = this.Convolve(SubInputs, this.Filters[X], this.StrideSchedule[X],false);

                this.DerivativeFeatureMaps.Add(this.ActivateDerivativeConvolutions(SubInputs, this.CNNActivationFunctionIDs[X]));
                //this.PrePoolFeatureMaps.Add(SubInputs);

                if(PoolFeatures)
                {
                    //SubInputs = this.PoolLayer(SubInputs, X, this.PoolingSchedule[X], true);
                }
                

                this.RawFeatureMaps.Add(SubInputs);
                //this.RawFeatureMaps[X] = this.NormalizeDataSet(this.RawFeatureMaps[X], 3);

                if(X >= 0)
                {
                    SubInputs = this.ActivateConvolutions(this.RawFeatureMaps[X], this.CNNActivationFunctionIDs[X]);
                }
                
                this.FeatureMaps.Add(SubInputs);
                //this.FeatureMaps[X] = this.NormalizeDataSet(this.FeatureMaps[X], 3);


                X++;
            }

            //this.GlobalIterator++;

            this.NeuralNetwork.ForwardPropagate(this.Flatten3DVector(this.FeatureMaps[this.FeatureMaps.Count - 1]),OutputNormalization,NormalizeOutputs);
         }

        public List<List<double>> ExpandVector(List<double> Input)
        {
            List<List<double>> FinalOutput = new List<List<double>>();
            List<List<double>> Output = new List<List<double>>();
            List<double> SubOutput = new List<double>();
            int X = 0;
            int Y = 0;
            int Z = 0;
            int Dims = (int)Math.Sqrt(Input.Count);

            //Y = Input.Count;
            //X = 0;
            //while(X < Y - (Math.Pow(Dims,2)))
            //{
            //    Input.Add(0);

            //    X++;
            //}


            //This needs to make an x y grid of rgbs
            while (Z < Input.Count)
            {
                X = 0;

                SubOutput.Add(Input[Z]);

                if ((Z) % Dims == 0 && Z != 0)
                {
                    FinalOutput.Add(SubOutput);
                    SubOutput = new List<double>();
                }

                Z++;
            }

            //Y = SubOutput.Count;
            //X = 0;
            //while (X < Dims - Y)
            //{
            //    SubOutput.Add(0);

            //    X++;
            //}

            //FinalOutput.Add(SubOutput);

            return FinalOutput;
        }

        public double CalculateL2()
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            int ZZ = 0;
            double L2 = 0;

            while(X < this.Filters.Count)
            {
                Y = 0;
                while(Y < this.Filters[X].Count)
                {
                    Z = 0;
                    while(Z < this.Filters[X][Y].Count)
                    {
                        ZZ = 0;
                        while(ZZ < this.Filters[X][Y][Z].Count)
                        {
                            L2 += Math.Pow(this.Filters[X][Y][Z][ZZ],2);

                            ZZ++;
                        }

                        Z++;
                    }

                    Y++;
                }

                X++;
            }


            return L2 * 0;

        }

        public List<List<List<double>>> ReshapeErrorTensor()
        {
            int NeuronCount = this.FeatureMaps[this.FeatureMaps.Count - 1].Count;
            int FeatureMapDim = (int)(Math.Sqrt(this.NeuralNetwork.Activations[0].Count / NeuronCount));
            List<double> SubSubTempList = new List<double>();
            List<List<double>> SubTempList = new List<List<double>>();
            List<List<List<double>>> TempList = new List<List<List<double>>>();
            int X = 0;
            int Y = 0;
            int Z = 0;

            while(X < this.NeuralNetwork.Errors[0].Count)
            {
                if(X > 0 && X % FeatureMapDim == 0)
                {
                    SubTempList.Add(SubSubTempList);
                    SubSubTempList = new List<double>();

                    if(SubTempList.Count % FeatureMapDim == 0)
                    {
                        TempList.Add(SubTempList);
                        SubTempList = new List<List<double>>();
                    }
                }               

                SubSubTempList.Add(this.NeuralNetwork.Errors[0][X]);

                X++;
            }

            SubTempList.Add(SubSubTempList);

            TempList.Add(SubTempList);

            return TempList;
        }



        public List<List<List<double>>> ElementWiseMultiply(List<List<List<double>>> Input1, List<List<List<double>>> Input2)
        {
            List<double> SubSubRetVal = new List<double>();
            List<List<double>> SubRetVal = new List<List<double>>();
            List<List<List<double>>> RetVal = new List<List<List<double>>>();
            int X = 0;
            int Y = 0;
            int Z = 0;

            while(X < Input1.Count)
            {
                SubRetVal = new List<List<double>>();
                Y = 0;
                while(Y < Input1[X].Count)
                {
                    SubSubRetVal = new List<double>();
                    Z = 0;
                    while(Z < Input1[X][Y].Count)
                    {
                        if(X < Input2.Count && Y < Input2[0].Count && Z < Input2[0][0].Count)
                        {
                            SubSubRetVal.Add(Input1[X][Y][Z] * Input2[X][Y][Z]);
                        }
                        else
                        {
                            //SubSubRetVal.Add(Input1[X][Y][Z]);
                            SubSubRetVal.Add(0);
                        }



                        Z++;
                    }

                    SubRetVal.Add(SubSubRetVal);

                    Y++;
                }

                RetVal.Add(SubRetVal);

                X++;
            }

            return RetVal;
        }

        public List<List<List<double>>> ElementWiseDivision(List<List<List<double>>> Input1, List<List<List<double>>> Input2)
        {
            List<double> SubSubRetVal = new List<double>();
            List<List<double>> SubRetVal = new List<List<double>>();
            List<List<List<double>>> RetVal = new List<List<List<double>>>();
            int X = 0;
            int Y = 0;
            int Z = 0;

            while (X < Input1.Count)
            {
                SubRetVal = new List<List<double>>();
                Y = 0;
                while (Y < Input1[X].Count)
                {
                    SubSubRetVal = new List<double>();
                    Z = 0;
                    while (Z < Input1[X][Y].Count)
                    {
                        if (X < Input2.Count && Y < Input2[0].Count && Z < Input2[0][0].Count)
                        {
                            SubSubRetVal.Add(Input1[X][Y][Z] / Input2[X][Y][Z]);
                        }
                        else
                        {
                            SubSubRetVal.Add(Input1[X][Y][Z]);
                            //SubSubRetVal.Add(0);
                        }



                        Z++;
                    }

                    SubRetVal.Add(SubSubRetVal);

                    Y++;
                }

                RetVal.Add(SubRetVal);

                X++;
            }

            return RetVal;
        }

        public List<List<double>> ElementWiseSummation(List<List<double>> Input1, List<List<double>> Input2)
        {
            List<double> SubSubRetVal = new List<double>();
            List<List<double>> SubRetVal = new List<List<double>>();
            List<List<List<double>>> RetVal = new List<List<List<double>>>();
            int X = 0;
            int Y = 0;
            int Z = 0;

            while (X < Input1.Count)
            {
                SubSubRetVal = new List<double>();
                Y = 0;
                while (Y < Input1[X].Count)
                {
                    SubSubRetVal.Add(Input1[X][Y] + Input2[X][Y]);

                    Y++;
                }

                SubRetVal.Add(SubSubRetVal);

                X++;
            }

            return SubRetVal;
        }

        public List<List<List<double>>> ResolveMaxPooling(List<List<List<double>>> InputLayer, int LayerID)
        {
            List<List<List<double>>> RetVal = new List<List<List<double>>>();
            List<List<double>> TempMap = new List<List<double>>();
            int X = 0;
            int Y = 0;
            int Z = 0;
            int A = 0;
            int B = 0;
            double GradientVal = 0;

            while (X < InputLayer.Count)
            {
                TempMap = this.CreateEmptyMap(this.FeatureMaps[Math.Max(0, LayerID - 1)][0].Count - 2);
                Y = 0;
                while (Y < InputLayer[X].Count)
                {
                    Z = 0;
                    while (Z < InputLayer[X][Y].Count)
                    {
                        A = 0;
                        while (A < this.PoolingSchedule[LayerID])
                        {
                            B = 0;
                            while (B < this.PoolingSchedule[LayerID])
                            {
                                if (Y * this.PoolingSchedule[LayerID] + A < TempMap.Count && Z * this.PoolingSchedule[LayerID] + B < TempMap.Count)
                                {
                                    TempMap[Y * this.PoolingSchedule[LayerID] + A][Z * this.PoolingSchedule[LayerID] + B] = (InputLayer[X][Y][Z] * this.MaxPoolGradients[LayerID][X][Y][Z]);
                                }


                                B++;
                            }

                            A++;
                        }


                        Z++;
                    }

                    Y++;
                }

                RetVal.Add(TempMap);

                X++;
            }

            return RetVal;
        }

        public List<List<double>> PadMap(List<List<double>> InputMap,int PaddingSize)
        {
            List<double> TempList1 = new List<double>();
            List<List<double>> TempList2 = new List<List<double>>();
            int X = 0;
            int Y = 0;

            while(X < InputMap.Count + (2 * PaddingSize))
            {
                TempList1 = new List<double>();
                Y = 0;
                while(Y < InputMap.Count + (2 * PaddingSize))
                {
                    TempList1.Add(0);

                    Y++;
                }

                TempList2.Add(TempList1);

                X++;
            }

            X = 0;
            while(X < InputMap.Count)
            {
                Y = 0;
                while(Y < InputMap[X].Count)
                {
                    TempList2[X + PaddingSize][Y + PaddingSize] = InputMap[X][Y];

                    Y++;
                }

                X++;
            }

            return TempList2;
        }

        public List<List<List<double>>> PadLayerMaps(List<List<List<double>>> InputLayerMaps,int PaddingSize)
        {
            List<List<List<double>>> RetVal = new List<List<List<double>>>();
            int X = 0;

            while(X < InputLayerMaps.Count)
            {
                RetVal.Add(PadMap(InputLayerMaps[X], PaddingSize));

                X++;
            }

            return RetVal;
        }


        public List<List<List<double>>> ReshapeTensor(List<double> Input,int MapCount)
        {
            List<List<double>> TempMap = new List<List<double>>();
            List<List<List<double>>> Output = new List<List<List<double>>>();
            List<double> TempList = new List<double>();
            int X = 0;
            int MapDimensions = (int)Math.Sqrt((int)(Input.Count / MapCount));

            while(X < Input.Count)
            {
                if(X > 0 && X % MapDimensions == 0)
                {
                    TempMap.Add(TempList);
                    TempList = new List<double>();
                }

                if(TempMap.Count > 0 && TempMap.Count % MapDimensions == 0)
                {
                    Output.Add(TempMap);
                    TempMap = new List<List<double>>();
                }

                TempList.Add(Input[X]);

                X++;
            }

            TempMap.Add(TempList);
            Output.Add(TempMap);

            return Output;
        }

        public List<List<List<double>>> CalculateGeneratorLoss(double DiscriminatorActivation,double DiscriminatorRawOutput)
        {
            List<List<List<double>>> Outputs = new List<List<List<double>>>();
            List<List<double>> TempList2 = new List<List<double>>();
            List<double> TempList1 = new List<double>();
            int X = 0;
            int Y = 0;
            int Z = 0;
            double TempVal = 0;

            while(Z < this.FeatureMaps[this.FeatureMaps.Count - 1].Count)
            {
                TempList2 = new List<List<double>>();
                X = 0;
                while (X < this.FeatureMaps[this.FeatureMaps.Count - 1][Z].Count)
                {
                    TempList1 = new List<double>();
                    Y = 0;
                    while (Y < this.FeatureMaps[this.FeatureMaps.Count - 1][Z][X].Count)
                    {
                        //TempVal = DiscriminatorActivation - 1.0f;
                        TempVal = -(1.0f / DiscriminatorActivation);
                        TempVal *= this.NeuralNetwork.ActivationFunctionDerivative(DiscriminatorRawOutput, 1);
                        TempVal *= DerivativeFeatureMaps[this.DerivativeFeatureMaps.Count - 1][Z][X][Y];
                        

                        TempList1.Add(TempVal);

                        Y++;
                    }

                    TempList2.Add(TempList1);

                    X++;
                }

                Outputs.Add(TempList2);

                Z++;
            }

            return Outputs;
        }

        public void BackPropagateGenerator(List<double> Inputs, List<double> Outputs, bool PoolActivations, bool TrainWeights, int WeightOptimizerID, int FilterOptimizerID, bool ErrorOnly = false, int OutputNormalization = 9, bool NormalizeOutputLayer = true, bool TrainFilters = true, double DiscriminatorActivation = 0, double DiscriminatorRawActivation = 0)
        {
            int X = this.Filters.Count - 1;
            int Y = 0;
            int Z = 0;
            int ZZ = 0;
            int ZZZ = 0;
            int ZZZZ = 0;
            int A = 0;
            int B = 0;
            int C = 0;
            int D = 0;
            int E = 0;
            int I = 0;
            int J = 0;
            int K = 0;
            List<double> LocalActivations = new List<double>();
            List<double> PreviousActivations = new List<double>();
            List<double> PreviousErrors = new List<double>();
            List<double> LocalErrors = new List<double>();
            List<double> PreviousWeights = new List<double>();
            List<double> Filters = new List<double>();
            List<double> TempList = new List<double>();
            List<List<double>> TempList2 = new List<List<double>>();
            List<List<List<List<double>>>> Errors = new List<List<List<List<double>>>>();
            List<List<List<double>>> SubErrors = new List<List<List<double>>>();
            List<List<List<double>>> BackpropErrors = new List<List<List<double>>>();
            List<List<double>> SubSubErrors = new List<List<double>>();
            List<double> SubSubSubErrors = new List<double>();

            List<List<List<double>>> FilterGradients = new List<List<List<double>>>();
            List<List<List<double>>> LocalGradients = new List<List<List<double>>>();
            List<List<List<double>>> ErrorGradients = new List<List<List<double>>>();
            List<List<List<double>>> NeuronGradients = new List<List<List<double>>>();
            List<List<List<double>>> DerivativeGradients = new List<List<List<double>>>();
            List<List<List<double>>> PrevLayerGradients = new List<List<List<double>>>();
            List<List<List<List<double>>>> NewFilters = this.Filters;
            List<List<List<double>>> SubFilters = new List<List<List<double>>>();
            List<List<List<double>>> SubFilters2 = new List<List<List<double>>>();
            List<List<double>> SubSubFilters = new List<List<double>>();
            List<double> SubSubSubFilters = new List<double>();
            Random Rnd = new Random();

            double Delta = 0;
            double NewDelta = 0;
            double ADAMDelta = 0;
            double SGDDelta = 0;
            double RMSPropDelta = 0;
            double TempVal1 = 0;
            double TempVal2 = 0;
            double TempVal3 = 0;
            int FunctionID = 0;
            double L2 = 0;
            int ZZZZMax = 0;
            //this.Errors = new List<List<List<List<double>>>>();

            this.FeedForwardGenerator((Inputs), PoolActivations, OutputNormalization, NormalizeOutputLayer);

            InitializeNetwork();


            E = this.Filters.Count - 1;

            while (E >= 0)
            {
                if (E == this.Filters.Count - 1)
                {
                    //SubFilters = new List<List<List<double>>>();
                    //SubFilters.Add(this.ExpandVector(Outputs));



                    NeuronGradients = CalculateGeneratorLoss(DiscriminatorActivation,DiscriminatorRawActivation);

                    //NeuronGradients = ResolveAveragePooling(SubFilters, E);
                    //NeuronGradients = SubFilters;

                    //NeuronGradients = this.ElementWiseMultiply(NeuronGradients, this.DerivativeFeatureMaps[E]);
                    FilterGradients = this.Convolve(this.FeatureMaps[E - 1], NeuronGradients, 1, false);

                    BackpropErrors = this.DeConvolve(NeuronGradients, this.Filters[E - 1], 1, this.Filters[E][0].Count - 1);
                }
                else
                {                   
                    //NeuronGradients = ResolveAveragePooling(SubFilters, E);
                    NeuronGradients = BackpropErrors;

                    //SubFilters = this.ElementWiseMultiply(SubFilters, this.MaxPoolGradients[E]);
                    if (E == 0)
                    {
                        LocalGradients = new List<List<List<double>>>();
                        LocalGradients.Add(this.ExpandVector(this.NeuralNetwork.Activations[this.NeuralNetwork.Activations.Count - 1]));

                        NeuronGradients = this.ElementWiseMultiply(NeuronGradients, this.DerivativeFeatureMaps[E]);
                        FilterGradients = this.Convolve(ReshapeTensor(this.NeuralNetwork.Activations[this.NeuralNetwork.Activations.Count - 1], this.Filters[0].Count), NeuronGradients, 1, false);

                        NeuronGradients = this.PadLayerMaps(NeuronGradients, this.Filters[0][0].Count - 1);

                    }
                    else
                    {
                        NeuronGradients = this.ElementWiseMultiply(NeuronGradients, this.DerivativeFeatureMaps[E]);
                        FilterGradients = this.Convolve(this.FeatureMaps[E - 1], NeuronGradients, 1, false);

                        BackpropErrors = this.DeConvolve(NeuronGradients, this.Filters[E - 1], 1, this.Filters[E][0].Count - 1);
                    }

                }

                this.Errors[E] = (NeuronGradients);

                if (TrainFilters)
                {
                    X = 0;
                    while (X < this.Filters[E].Count)
                    {
                        Y = 0;
                        while (Y < this.Filters[E][X].Count)
                        {
                            Z = 0;
                            while (Z < this.Filters[E][X][Y].Count)
                            {
                                switch (FilterOptimizerID)
                                {
                                    case 0:
                                        SGDDelta = FilterGradients[X][Y][Z];

                                        //this.Filters[E][X][Y][Z] = this.Filters[E][X][Y][Z] - (SGDDelta + (0 * this.PrevDeltas[E][X][Y][Z]));

                                        this.CurrentDeltas[E][X][Y][Z] += FilterGradients[X][Y][Z];
                                        this.PrevDeltas[E][X][Y][Z] += FilterGradients[X][Y][Z];
                                        break;

                                    case 1:
                                        TempVal1 = (this.NeuralNetwork.RMSPropConst * this.PrevDeltas[E][X][Y][Z]) + (Math.Pow(FilterGradients[X][Y][Z], 2) * (1 - this.NeuralNetwork.RMSPropConst));
                                        this.PrevDeltas[E][X][Y][Z] = TempVal1;
                                        RMSPropDelta = this.LearningRate / (Math.Sqrt(TempVal1 + 0.00000000000000001)) * FilterGradients[X][Y][Z];
                                        //this.Filters[E][X][Y][Z] = this.Filters[E][X][Y][Z] - RMSPropDelta;

                                        this.CurrentDeltas[E][X][Y][Z] = RMSPropDelta;
                                        break;

                                    case 2:
                                        this.FiltersM[E][X][Y][Z] = (this.NeuralNetwork.B1 * this.FiltersM[E][X][Y][Z] + (1 - this.NeuralNetwork.B1) * FilterGradients[X][Y][Z]);
                                        this.FiltersV[E][X][Y][Z] = (this.NeuralNetwork.B2 * this.FiltersV[E][X][Y][Z] + (1 - this.NeuralNetwork.B2) * Math.Pow(FilterGradients[X][Y][Z], 2));
                                        ADAMDelta = (this.FiltersM[E][X][Y][Z] / (1 - this.NeuralNetwork.B1)) / Math.Sqrt((this.FiltersV[E][X][Y][Z] / (1 - this.NeuralNetwork.B2)) + 0.00000000000000001);
                                        this.CurrentDeltas[E][X][Y][Z] += ADAMDelta;
                                        //this.Filters[E][X][Y][Z] = this.Filters[E][X][Y][Z] - this.LearningRate * ADAMDelta;
                                        break;
                                }

                                Z++;
                            }

                            Y++;
                        }

                        X++;
                    }
                }

                //NormalizeFilters(E);


                E--;
            }

            //NeuronGradients = this.PoolMaps(this.Errors[0]);
            this.NeuralNetwork.BackPropagate((Inputs), this.Flatten3DVector((this.Errors[0])), OutputNormalization, TrainWeights, WeightOptimizerID, ErrorOnly, NormalizeOutputLayer, DiscriminatorActivation, DiscriminatorRawActivation);


            this.GlobalIterator++;
        }

        public List<List<List<double>>> CreateEmptyLayerMaps(int MapDimensions, int MapCount, double InitVal)
        {
            int X = 0;
            List<List<List<double>>> Outputs = new List<List<List<double>>>();

            while(X < MapCount)
            {
                Outputs.Add(CreateEmptyMap(MapDimensions,InitVal));

                X++;
            }

            return Outputs;
        }

        public List<List<List<double>>> ResolveAveragePooling(List<List<List<double>>> InputLayer,int LayerID)
        {
            List<List<List<double>>> RetVal = new List<List<List<double>>>();
            List<List<double>> TempMap = new List<List<double>>();
            int X = 0;
            int Y = 0;
            int Z = 0;
            int A = 0;
            int B = 0;
            double GradientVal = 0;

            while (X < InputLayer.Count)
            {
                TempMap = this.CreateEmptyMap(this.DerivativeFeatureMaps[(LayerID)][0].Count);
                Y = 0;
                while(Y < InputLayer[X].Count)
                {
                    Z = 0;
                    while(Z < InputLayer[X][Y].Count)
                    {
                        A = 0;
                        while(A < this.PoolingSchedule[LayerID])
                        {
                            B = 0;
                            while(B < this.PoolingSchedule[LayerID])
                            {
                                if(Y * this.PoolingSchedule[LayerID] + A < TempMap.Count && Z * this.PoolingSchedule[LayerID] + B < TempMap.Count)
                                {
                                    TempMap[Y * this.PoolingSchedule[LayerID] + A][Z * this.PoolingSchedule[LayerID] + B] = InputLayer[X][Y][Z];
                                }
                                

                                B++;
                            }

                            A++;
                        }


                        Z++;
                    }

                    Y++;
                }

                RetVal.Add(TempMap);

                X++;
            }

            return RetVal;
        }

        public void BackPropagate(List<List<double>> Inputs, List<double> Outputs, bool PoolActivations, bool TrainWeights, int WeightOptimizerID, int FilterOptimizerID, bool ErrorOnly = false, int OutputNormalization = 9, bool NormalizeOutputLayer = true, bool TrainFilters = true, double DiscriminatorActivation = 0, double DiscriminatorRawActivation = 0)
        {
            int X = this.Filters.Count - 1;
            int Y = 0;
            int Z = 0;
            int ZZ = 0;
            int ZZZ = 0;
            int ZZZZ = 0;
            int A = 0;
            int B = 0;
            int C = 0;
            int D = 0;
            int E = 0;
            int I = 0;
            int J = 0;
            int K = 0;
            List<double> LocalActivations = new List<double>();
            List<double> PreviousActivations = new List<double>();
            List<double> PreviousErrors = new List<double>();
            List<double> LocalErrors = new List<double>();
            List<double> PreviousWeights = new List<double>();
            List<double> Filters = new List<double>();
            List<double> TempList = new List<double>();
            List<List<double>> TempList2 = new List<List<double>>();
            List<List<List<List<double>>>> Errors = new List<List<List<List<double>>>>();
            List<List<List<double>>> SubErrors = new List<List<List<double>>>();
            List<List<List<double>>> BackpropErrors = new List<List<List<double>>>();
            List<List<double>> SubSubErrors = new List<List<double>>();
            List<double> SubSubSubErrors = new List<double>();

            List<List<List<double>>> FilterGradients = new List<List<List<double>>>();
            List<List<List<double>>> LocalGradients = new List<List<List<double>>>();
            List<List<List<double>>> ErrorGradients = new List<List<List<double>>>();
            List<List<List<double>>> NeuronGradients = new List<List<List<double>>>();
            List<List<List<double>>> DerivativeGradients = new List<List<List<double>>>();
            List<List<List<double>>> PrevLayerGradients = new List<List<List<double>>>();
            List<List<List<List<double>>>> NewFilters = this.Filters;
            List<List<List<double>>> SubFilters = new List<List<List<double>>>();
            List<List<List<double>>> SubFilters2 = new List<List<List<double>>>();
            List<List<double>> SubSubFilters = new List<List<double>>();
            List<double> SubSubSubFilters = new List<double>();
            Random Rnd = new Random();

            double Delta = 0;
            double NewDelta = 0;
            double ADAMDelta = 0;
            double SGDDelta = 0;
            double RMSPropDelta = 0;
            double TempVal1 = 0;
            double TempVal2 = 0;
            double TempVal3 = 0;
            int FunctionID = 0;
            double L2 = 0;
            int ZZZZMax = 0;
            //this.Errors = new List<List<List<List<double>>>>();

            this.FeedForward(Inputs, PoolActivations, OutputNormalization, NormalizeOutputLayer);

            InitializeNetwork();

            this.NeuralNetwork.BackPropagate(this.Flatten3DVector(this.FeatureMaps[this.FeatureMaps.Count - 1]), Outputs, OutputNormalization, TrainWeights, WeightOptimizerID, ErrorOnly, NormalizeOutputLayer, DiscriminatorActivation, DiscriminatorRawActivation);

            E = this.Filters.Count - 1;

            while (E >= 0)
            {
                if (E == this.Filters.Count - 1)
                {
                    SubFilters = ReshapeTensor(this.NeuralNetwork.Errors[0], this.FeatureMaps[E].Count);

                    //NeuronGradients = ResolveAveragePooling(SubFilters, E);
                    NeuronGradients = SubFilters;
                    NeuronGradients = this.ElementWiseMultiply(NeuronGradients, this.DerivativeFeatureMaps[E]);
                    FilterGradients = this.Convolve(this.FeatureMaps[E - 1], NeuronGradients, 1, false);
                  
                    BackpropErrors = this.DeConvolve(NeuronGradients, this.Filters[E-1], 1, this.Filters[E][0].Count - 1 );
                    
                    
                }
                else
                {
                    //NeuronGradients = ResolveAveragePooling(SubFilters, E);
                    NeuronGradients = BackpropErrors;

                    //SubFilters = this.ElementWiseMultiply(SubFilters, this.MaxPoolGradients[E]);
                    if (E == 0)
                    {
                        LocalGradients = new List<List<List<double>>>();
                        LocalGradients.Add(Inputs);

                        NeuronGradients = this.ElementWiseMultiply(NeuronGradients, this.DerivativeFeatureMaps[E]);
                        FilterGradients = this.Convolve(LocalGradients, NeuronGradients, 1, false);
                        //NeuronGradients = this.DeConvolve(NeuronGradients, this.Filters[E], 1, this.Filters[E][0].Count - 1);                       
                    }
                    else
                    {
                        NeuronGradients = this.ElementWiseMultiply(NeuronGradients, this.DerivativeFeatureMaps[E]);
                        FilterGradients = this.Convolve(this.FeatureMaps[E - 1], NeuronGradients, 1, false);
                        BackpropErrors = this.DeConvolve(NeuronGradients, this.Filters[E-1], 1, this.Filters[E][0].Count - 1);


                        //Remember to switch back
                        
                    }

                }

                this.Errors[E] = (NeuronGradients);

                if (TrainFilters)
                {
                    X = 0;
                    while (X < this.Filters[E].Count)
                    {
                        Y = 0;
                        while (Y < this.Filters[E][X].Count)
                        {
                            Z = 0;
                            while (Z < this.Filters[E][X][Y].Count)
                            {
                                switch (FilterOptimizerID)
                                {
                                    case 0:
                                        SGDDelta = FilterGradients[X][Y][Z];

                                        //this.Filters[E][X][Y][Z] = this.Filters[E][X][Y][Z] - (SGDDelta + (0 * this.PrevDeltas[E][X][Y][Z]));

                                        this.CurrentDeltas[E][X][Y][Z] += FilterGradients[X][Y][Z];
                                        this.PrevDeltas[E][X][Y][Z] += FilterGradients[X][Y][Z];
                                        break;

                                    case 1:
                                        TempVal1 = (this.NeuralNetwork.RMSPropConst * this.PrevDeltas[E][X][Y][Z]) + (Math.Pow(FilterGradients[X][Y][Z], 2) * (1 - this.NeuralNetwork.RMSPropConst));
                                        this.PrevDeltas[E][X][Y][Z] = TempVal1;
                                        RMSPropDelta = this.LearningRate / (Math.Sqrt(TempVal1 + 0.00000000000000001)) * FilterGradients[X][Y][Z];
                                        //this.Filters[E][X][Y][Z] = this.Filters[E][X][Y][Z] - RMSPropDelta;

                                        this.CurrentDeltas[E][X][Y][Z] = RMSPropDelta;
                                        break;

                                    case 2:
                                        this.FiltersM[E][X][Y][Z] = (this.NeuralNetwork.B1 * this.FiltersM[E][X][Y][Z] + (1 - this.NeuralNetwork.B1) * FilterGradients[X][Y][Z]);
                                        this.FiltersV[E][X][Y][Z] = (this.NeuralNetwork.B2 * this.FiltersV[E][X][Y][Z] + (1 - this.NeuralNetwork.B2) * Math.Pow(FilterGradients[X][Y][Z], 2));
                                        ADAMDelta = (this.FiltersM[E][X][Y][Z] / (1 - this.NeuralNetwork.B1)) / Math.Sqrt((this.FiltersV[E][X][Y][Z] / (1 - this.NeuralNetwork.B2)) + 0.00000000000000001);
                                        this.CurrentDeltas[E][X][Y][Z] += ADAMDelta;
                                        //this.Filters[E][X][Y][Z] = this.Filters[E][X][Y][Z] - this.LearningRate * ADAMDelta;
                                        break;
                                }

                                Z++;
                            }

                            Y++;
                        }

                        X++;
                    }
                }

                //NormalizeFilters(E);


                E--;
            }

            this.GlobalIterator++;
        }

        public void ApplyGradients(int BatchSize)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            int ZZ = 0;

            while(X < this.Filters.Count)
            {
                Y = 0;
                while(Y < this.Filters[X].Count)
                {
                    Z = 0;
                    while(Z < this.Filters[X][Y].Count)
                    {
                        ZZ = 0;
                        while(ZZ < this.Filters[X][Y][Z].Count)
                        {
                            this.Filters[X][Y][Z][ZZ] = this.Filters[X][Y][Z][ZZ] - ((this.CurrentDeltas[X][Y][Z][ZZ]/BatchSize) * this.NeuralNetwork.LearningRate);
                            this.CurrentDeltas[X][Y][Z][ZZ] = 0;

                            ZZ++;
                        }

                        Z++;
                    }

                    Y++;
                }

                X++;
            }

            //ResetStoredAdamValues();
        }

        public void ResetStoredAdamValues()
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            int ZZ = 0;

            while (X < this.FiltersM.Count)
            {
                Y = 0;
                while (Y < this.FiltersM[X].Count)
                {
                    Z = 0;
                    while (Z < this.FiltersM[X][Y].Count)
                    {
                        ZZ = 0;
                        while (ZZ < this.FiltersM[X][Y][Z].Count)
                        {
                            this.FiltersM[X][Y][Z][ZZ] = 0;
                            this.FiltersV[X][Y][Z][ZZ] = 0;

                            ZZ++;
                        }

                        Z++;
                    }

                    Y++;
                }

                X++;
            }
        }

        public double GetFilterVariance(int LayerID)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            double RetVal = 0;
            double Mean = 0;
            int Counter = 0;

            while(X < this.Filters[LayerID].Count)
            {
                Y = 0;
                while(Y < this.Filters[LayerID][X].Count)
                {
                    Z = 0;
                    while(Z < this.Filters[LayerID][X][Y].Count)
                    {
                        Mean += this.Filters[LayerID][X][Y][Z];
                        Counter++;

                        Z++;
                    }

                    Y++;
                }

                X++;
            }

            X = 0;
            while (X < this.Filters[LayerID].Count)
            {
                Y = 0;
                while (Y < this.Filters[LayerID][X].Count)
                {
                    Z = 0;
                    while (Z < this.Filters[LayerID][X][Y].Count)
                    {
                        RetVal += Math.Pow(this.Filters[LayerID][X][Y][Z] - Mean,2);

                        Z++;
                    }

                    Y++;
                }

                X++;
            }

            return (1.0f / Counter) * RetVal;
        }

        public List<List<List<double>>> UpscaleGradients(List<List<List<double>>> Input,int DesiredDims,int KernelSize)
        {
            int X = 0;
            List<List<List<double>>> RetVal = new List<List<List<double>>>();

            while (X < Input.Count)
            {
                RetVal.Add(KNearestNeighborUpscale(Input[X],DesiredDims,KernelSize));

                X++;
            }

            return RetVal;
        }

        public List<List<double>> KNearestNeighborUpscale(List<List<double>> Input,int DestinationDims,int KernelSize)
        {
            List<List<double>> RetVal = new List<List<double>>();
            List<double> TempRow = new List<double>();
            int X = 0;
            int Y = 0;
            int A = 0;
            int B = 0;
            double TempVal = 0;

            while(X < DestinationDims)
            {
                TempRow = new List<double>();
                Y = 0;
                while(Y < DestinationDims)
                {
                    TempRow.Add(0);

                    Y++;
                }

                RetVal.Add(TempRow);

                X++;
            }


            X = 0;
            while(X < Input.Count - KernelSize)
            {
                Y = 0;
                while(Y < Input[X].Count - KernelSize)
                {
                    TempVal = Input[X][Y];
                    //RetVal[X][Y] = TempVal;
                    A = 0;
                    while(A < KernelSize)
                    {
                        B = 0;
                        while (B < KernelSize)
                        {
                            RetVal[(X*KernelSize) + A][(Y*KernelSize) + B] = TempVal;

                            B++;
                        }

                        A++;
                    }

                    Y++;
                }

                X++;
            }

            return RetVal;
        }

        public double CalculateStandardDeviation(List<List<double>> Inputs, double Mean = 0.0f)
        {
            double Variance = 0;
            int X = 0;
            int Y = 0;
            int Z = 0;
            int Counter = 0;

            if (Mean == 0)
            {
                while (X < Inputs.Count)
                {
                    Y = 0;
                    while (Y < Inputs[X].Count)
                    {
                        Mean += Inputs[X][Y];
                        Counter++;

                        Y++;
                    }

                    X++;
                }

                Mean /= Counter;
            }

            X = 0;
            while (X < Inputs.Count)
            {
                Y = 0;
                while (Y < Inputs[X].Count)
                {
                    Variance += Math.Pow(Inputs[X][Y] - Mean, 2);

                    Y++;
                }

                X++;
            }

            Variance /= (Inputs.Count * Inputs[0].Count);

            return Math.Sqrt(Variance);
        }

        public double CalculateStandardDeviation(List<List<List<double>>> Inputs, double Mean = 0.0f)
        {
            double Variance = 0;
            int X = 0;
            int Y = 0;
            int Z = 0;

            if (Mean == 0)
            {
                while (X < Inputs.Count)
                {
                    Y = 0;
                    while(Y < Inputs[X].Count)
                    {
                        Z = 0;
                        while(Z < Inputs[X][Y].Count)
                        {
                            Mean += Inputs[X][Y][Z];

                            Z++;
                        }

                        Y++;
                    }                    

                    X++;
                }

                Mean /= (Inputs.Count * (Inputs[0].Count * Inputs[0][0].Count));
            }

            X = 0;
            while (X < Inputs.Count)
            {
                Y = 0;
                while (Y < Inputs[X].Count)
                {
                    Z = 0;
                    while (Z < Inputs[X][Y].Count)
                    {
                        Variance += Math.Pow(Inputs[X][Y][Z]-Mean,2);

                        Z++;
                    }

                    Y++;
                }

                X++;
            }           

            Variance /= (Inputs.Count * (Inputs[0].Count * Inputs[0][0].Count));

            return Math.Sqrt(Variance);
        }

        public double ZScore(List<List<List<double>>> Inputs, double SamplePoint, double Mean = 0.0f)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;

            if (Mean == 0)
            {
                while (X < Inputs.Count)
                {
                    Y = 0;
                    while(Y < Inputs[X].Count)
                    {
                        Z = 0;
                        while(Z < Inputs[X][Y].Count)
                        {
                            Mean += Inputs[X][Y][Z];

                            Z++;
                        }

                        Y++;
                    }                    

                    X++;
                }

                Mean /= (Inputs.Count * (Inputs[0].Count * Inputs[0][0].Count));
            }

            return (SamplePoint - Mean) / CalculateStandardDeviation(Inputs);
        }

        public List<List<double>> NormalizeDataSet(List<List<double>> Inputs, int NormalizationType = 4)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            double Mean = 0;
            double StdDev = 0;

            while (X < Inputs.Count)
            {
                Y = 0;
                while (Y < Inputs[X].Count)
                {
                    Mean += Inputs[X][Y];

                    Y++;
                }

                X++;
            }

            Mean /= (Inputs.Count * (Inputs[0].Count * Inputs[0].Count));
            StdDev = CalculateStandardDeviation(Inputs, Mean);

            this.FilterMean = Mean;
            this.FilterVariance = StdDev;

            X = 0;
            while (X < Inputs.Count)
            {
                Y = 0;
                while (Y < Inputs[X].Count)
                {
                    Inputs[X][Y] = (Inputs[X][Y] - Mean) / Math.Sqrt(StdDev);

                    Y++;
                }

                X++;
            }

            return Inputs;
        }

        public List<List<List<double>>> NormalizeDataSet(List<List<List<double>>> Inputs,int NormalizationType = 4)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            double Mean = 0;
            double StdDev = 0;
            int Counter = 0;
            double MaxVal = Inputs[0][0][0];
            double MinVal = Inputs[0][0][0];

            while(X < Inputs.Count)
            {
                Y = 0;
                while(Y < Inputs[X].Count)
                {
                    Z = 0;
                    while(Z < Inputs[X][Y].Count)
                    {
                        Mean += Inputs[X][Y][Z];

                        if (Inputs[X][Y][Z] > MaxVal)
                        {
                            MaxVal = Inputs[X][Y][Z];
                        }

                        if (Inputs[X][Y][Z] < MinVal)
                        {
                            MinVal = Inputs[X][Y][Z];
                        }

                        Counter++;

                        Z++;
                    }

                    Y++;
                }

                X++;
            }

            Mean /= Counter;
            StdDev = CalculateStandardDeviation(Inputs, Mean);

            this.FilterMean = Mean;
            this.FilterVariance = StdDev;

            X = 0;
            while (X < Inputs.Count)
            {
                Y = 0;
                while (Y < Inputs[X].Count)
                {
                    Z = 0;
                    while (Z < Inputs[X][Y].Count)
                    {
                        switch(NormalizationType)
                        {
                            case 0:
                                Inputs[X][Y][Z] = Math.Tanh(Inputs[X][Y][Z]);
                                break;
                            case 3:
                                Inputs[X][Y][Z] = (Inputs[X][Y][Z] - MinVal) / (MaxVal - MinVal);
                                break;
                            case 4:
                                Inputs[X][Y][Z] = (Inputs[X][Y][Z] - Mean) / (StdDev);
                                break;
                        }
                        

                        Z++;
                    }

                    Y++;
                }

                X++;
            }

            return Inputs;
        }

        public void NormalizeActivations()
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            int ZZ = 0;
            int A = 0;
            int B = 0;
            List<double> DataSet = new List<double>();

            while(X< this.FeatureMaps.Count)
            {
                this.FeatureMaps[X] = NormalizeDataSet(this.FeatureMaps[X]);

                X++;
            }

        }

        public void NormalizeActivations(int LayerID)
        {
            int X = 1;
            int Y = 0;
            int Z = 0;
            int ZZ = 0;
            int A = 0;
            int B = 0;
            int TempFilter = 0;
            int TempFilterY = 0;
            int TempFilterX = 0;
            List<double> DataSet = new List<double>();

            DataSet = new List<double>();
            Y = 0;
            while (Y < this.FeatureMaps[LayerID].Count)
            {
                Z = 0;
                while (Z < this.FeatureMaps[LayerID][Y].Count)
                {
                    ZZ = 0;
                    while (ZZ < this.FeatureMaps[LayerID][Y][Z].Count)
                    {
                        DataSet.Add(this.FeatureMaps[LayerID][Y][Z][ZZ]);

                        ZZ++;
                    }

                    Z++;
                }

                Y++;
            }

            DataSet = this.NeuralNetwork.NormalizeDataSet(DataSet, 5);

            A = 0;
            while (A < DataSet.Count)
            {
                TempFilter = (int)(A / Math.Pow(this.FeatureMaps[LayerID][0].Count, 2));
                TempFilterY = (int)(A / this.FeatureMaps[LayerID][0].Count) % this.FeatureMaps[LayerID][TempFilter].Count;
                TempFilterX = (int)(A % this.FeatureMaps[LayerID][TempFilter][TempFilterY].Count);


                this.FeatureMaps[LayerID][TempFilter][TempFilterY][TempFilterX] = DataSet[A];

                A++;
            }
        }

        public void NormalizeDerivativeActivations(int LayerID)
        {
            int X = 1;
            int Y = 0;
            int Z = 0;
            int ZZ = 0;
            int A = 0;
            int B = 0;
            int TempFilter = 0;
            int TempFilterY = 0;
            int TempFilterX = 0;
            List<double> DataSet = new List<double>();

            DataSet = new List<double>();
            Y = 0;
            while (Y < this.DerivativeFeatureMaps[LayerID].Count)
            {
                Z = 0;
                while (Z < this.DerivativeFeatureMaps[LayerID][Y].Count)
                {
                    ZZ = 0;
                    while (ZZ < this.DerivativeFeatureMaps[LayerID][Y][Z].Count)
                    {
                        DataSet.Add(this.DerivativeFeatureMaps[LayerID][Y][Z][ZZ]);

                        ZZ++;
                    }

                    Z++;
                }

                Y++;
            }

            DataSet = this.NeuralNetwork.NormalizeDataSet(DataSet, 5);

            A = 0;
            while (A < DataSet.Count)
            {
                TempFilter = (int)(A / Math.Pow(this.DerivativeFeatureMaps[LayerID][0].Count, 2));
                TempFilterY = (int)(A / this.DerivativeFeatureMaps[LayerID][0].Count) % this.DerivativeFeatureMaps[LayerID][TempFilter].Count;
                TempFilterX = (int)(A % this.DerivativeFeatureMaps[LayerID][TempFilter][TempFilterY].Count);


                this.DerivativeFeatureMaps[LayerID][TempFilter][TempFilterY][TempFilterX] = DataSet[A];

                A++;
            }
        }

        public void NormalizeErrors(int LayerID)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            int ZZ = 0;
            int A = 0;
            int B = 0;
            int TempFilter = 0;
            int TempFilterY = 0;
            int TempFilterX = 0;
            List<double> DataSet = new List<double>();

            DataSet = new List<double>();
            Y = 0;
            while (Y < this.FeatureMaps[LayerID].Count)
            {
                Z = 0;
                while (Z < this.FeatureMaps[LayerID][Y].Count)
                {
                    ZZ = 0;
                    while (ZZ < this.FeatureMaps[LayerID][Y][Z].Count)
                    {
                        DataSet.Add(this.FeatureMaps[LayerID][Y][Z][ZZ]);

                        ZZ++;
                    }

                    Z++;
                }

                Y++;
            }

            DataSet = this.NeuralNetwork.NormalizeDataSet(DataSet, 4);

            A = 0;
            while (A < DataSet.Count)
            {
                TempFilter = (int)(A / Math.Pow(this.FeatureMaps[LayerID][0].Count, 2));
                TempFilterY = (int)(A / this.FeatureMaps[LayerID][0].Count) % this.FeatureMaps[LayerID][TempFilter].Count;
                TempFilterX = (int)(A % this.FeatureMaps[LayerID][TempFilter][TempFilterY].Count);


                this.FeatureMaps[LayerID][TempFilter][TempFilterY][TempFilterX] = DataSet[A];

                A++;
            }

        }

        public void NormalizeErrors()
        {
            int X = 1;
            int Y = 0;
            int Z = 0;
            int ZZ = 0;
            int A = 0;
            int B = 0;
            int TempFilter = 0;
            int TempFilterY = 0;
            int TempFilterX = 0;
            List<double> DataSet = new List<double>();

            while (X < this.Errors.Count)
            {
                DataSet = new List<double>();
                Y = 0;
                while (Y < this.Errors[X].Count)
                {
                    Z = 0;
                    while (Z < this.Errors[X][Y].Count)
                    {
                        ZZ = 0;
                        while (ZZ < this.Errors[X][Y][Z].Count)
                        {
                            DataSet.Add(this.Errors[X][Y][Z][ZZ]);

                            ZZ++;
                        }

                        Z++;
                    }

                    Y++;
                }

                DataSet = this.NeuralNetwork.NormalizeDataSet(DataSet, 4);

                A = 0;
                while (A < DataSet.Count)
                {
                    TempFilter = (int)(A / Math.Pow(this.Errors[X][0].Count, 2));
                    TempFilterY = (int)(A / this.Errors[X][0].Count) % this.Errors[X][TempFilter].Count;
                    TempFilterX = (int)(A % this.Errors[X][TempFilter][TempFilterY].Count);


                    this.Errors[X][TempFilter][TempFilterY][TempFilterX] = DataSet[A];

                    A++;
                }

                X++;
            }
        }

        public void NormalizeFilters()
        {
            int X = 1;
            int Y = 0;
            int Z = 0;
            int ZZ = 0;
            int A = 0;
            int B = 0;
            int TempFilter = 0;
            int TempFilterY = 0;
            int TempFilterX = 0;
            List<double> DataSet = new List<double>();

            X = 0;
            while(X < this.Filters.Count)
            {
                this.Filters[X] = NormalizeDataSet(this.Filters[X]);

                X++;
            }
        }

        public void NormalizeFilters(int LayerID)
        {
            int X = 1;
            int Y = 0;
            int Z = 0;
            int ZZ = 0;
            int A = 0;
            int B = 0;
            int TempFilter = 0;
            int TempFilterY = 0;
            int TempFilterX = 0;
            List<double> DataSet = new List<double>();

            DataSet = new List<double>();
            Y = 0;
            while (Y < this.Filters[LayerID].Count)
            {
                Z = 0;
                while (Z < this.Filters[LayerID][Y].Count)
                {
                    ZZ = 0;
                    while(ZZ < this.Filters[LayerID][Y][Z].Count)
                    {
                        DataSet.Add(this.Filters[LayerID][Y][Z][ZZ]);

                        ZZ++;
                    }

                    Z++;
                }

                Y++;
            }

            DataSet = this.NeuralNetwork.NormalizeDataSet(DataSet,3);

            A = 0;
            while(A < DataSet.Count)
            {
                TempFilter = (int)(A / Math.Pow(this.Filters[LayerID][0].Count,2));
                TempFilterY = (int)(A / this.Filters[LayerID][0].Count) % this.Filters[LayerID][TempFilter].Count;
                TempFilterX = (int)(A % this.Filters[LayerID][TempFilter][TempFilterY].Count);


                this.Filters[LayerID][TempFilter][TempFilterY][TempFilterX] = DataSet[A];

                A++;
            }

        }

        public List<List<List<double>>> AvgValues(List<List<List<double>>> Inputs,int Iterations)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;

            while(X < Inputs.Count)
            {
                Y = 0;
                while(Y < Inputs[X].Count)
                {
                    Z = 0;
                    while(Z < Inputs[X][Y].Count)
                    {
                        Inputs[X][Y][Z] /= Iterations;

                        Z++;
                    }

                    Y++;
                }

                X++;
            }

            return Inputs;
        }

        public List<List<double>> CopyFeatures(List<List<double>> Input)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            List<List<double>> TempList2 = new List<List<double>>();
            List<double> TempList = new List<double>();

            while(X < Input.Count)
            {
                TempList = new List<double>();
                Y = 0;
                while(Y < Input[X].Count)
                {
                    TempList.Add((double)Input[X][Y]);

                    Y++;
                }

                TempList2.Add(TempList);

                X++;
            }

            return TempList2;
        }

        public List<List<List<double>>> PoolGradients(List<List<List<double>>> Input, List<List<List<double>>> Filters, int KernelSize)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            int A = 0;
            int B = 0;
            int Counter = 0;
            int XPooling = (int)Math.Max(1,(Input.Count / Filters.Count));
            int YPooling = (int)Math.Max(1,Input[0].Count / Filters[0].Count);
            int ZPooling = (int)(Math.Max(1,Input[0][0].Count / Filters[0][0].Count));
            List<List<List<double>>> RetVal = new List<List<List<double>>>();
            List<List<List<double>>> TempList4 = new List<List<List<double>>>();
            List<List<double>> TempList3 = new List<List<double>>();
            List<List<double>> TempList2 = new List<List<double>>();
            List<double> TempList = new List<double>();
            double TempVal = 0;

            if(Filters.Count > Input.Count || Filters[0].Count > Input[0].Count || Filters[0][0].Count > Input[0][0].Count)
            {
                return Input;
            }

            X = 0;
            while(X < Input.Count)
            {
                TempList2 = this.CopyFeatures(Input[X]);
                Y = 0;
                while(Y < Input[X].Count)
                {
                    Z = 0;
                    while(Z < Input[X][Y].Count)
                    {
                        TempVal = Math.Abs(Input[X][Y][Z]);
                        A = 1;
                        while(A < XPooling)
                        {
                            if (Math.Abs(Input[X + A][Y][Z]) > Math.Abs(TempVal))
                            {
                                //TempVal = Input[X + A][Y][Z];
                            }

                            TempVal += Input[X + A][Y][Z];

                            A++;
                        }

                        //TempVal /= XPooling;

                        TempList2[Y][Z] = TempVal;

                        Z++;
                    }

                    Y++;
                }

                RetVal.Add(TempList2);

                X+=XPooling;
            }


            X = 0;
            while(X < RetVal.Count)
            {
                TempList3 = new List<List<double>>();
                //Pool along Y/Z
                Y = 0;
                while (Y < RetVal[X].Count)
                {
                    TempList = new List<double>();
                    Z = 0;
                    while (Z < RetVal[X][Y].Count)
                    {

                        Counter = 0;
                        TempVal = Math.Abs(RetVal[X][Y][Z]);
                        A = 0;
                        while (A < YPooling)
                        {
                            B = 0;
                            while (B < ZPooling)
                            {
                                if (Y + A < RetVal[X].Count && Z + B < RetVal[X][Y].Count)
                                {
                                    if (Math.Abs(RetVal[X][Y + A][Z + B]) > Math.Abs(TempVal))
                                    {
                                        //TempVal = RetVal[X][Y + A][Z + B];
                                    }
                                    TempVal += TempList2[Y + A][Z + B];
                                    Counter++;
                                }

                                B++;
                            }

                            A++;
                        }

                        //TempVal /= Counter;

                        TempList.Add(TempVal);

                        Z += ZPooling;
                    }

                    TempList3.Add(TempList);

                    Y += YPooling;
                }

                TempList4.Add(TempList3);

                X++;
            }
            


            return TempList4;
        }

        public List<List<List<double>>> MaxGradients(List<List<List<double>>> Input,List<List<List<double>>> Filters, int KernelSize,int LayerID)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            int A = 0;
            int B = 0;
            int C = 0;
            double MaxVal = 0;
            double AvgVal = 0;
            List<List<double>> RetVal = new List<List<double>>();
            List<double> TempVals = new List<double>();
            List<List<List<double>>> FinalRetVal = new List<List<List<double>>>();
            List<List<List<double>>> Input2 = new List<List<List<double>>>();
            int XPooling = (int)(Input.Count/ Filters.Count);
            int YPooling = (int)(Input[0].Count / Filters[0].Count);
            int ZPooling = (int)(Input[0][0].Count / Filters[0][0].Count);

            while(X < Input.Count)
            {
                Input[X] = this.PoolFeature(Input[X], KernelSize);

                X++;
            }

            X = 0;
            while(X < Filters.Count)
            {
                FinalRetVal.Add(Input[X]);

                X++;
            }

            return FinalRetVal;
        }

        public List<List<double>> PoolFeature2(List<List<double>> Input, int KernelSize)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            int A = 0;
            int B = 0;
            double MaxVal = 0;
            double AvgVal = 0;
            List<List<double>> RetVal = new List<List<double>>();
            List<double> TempVals = new List<double>();
            List<List<List<double>>> FinalRetVal = new List<List<List<double>>>();

            RetVal = this.CopyFeatures(Input);

            X = 0;
            while (X < Input.Count)
            {
                TempVals = new List<double>();
                Y = 0;
                while (Y < Input[X].Count)
                {
                    AvgVal = 0;
                    MaxVal = Input[X][Y];
                    A = 0;
                    while (A < KernelSize)
                    {
                        B = 0;
                        while (B < KernelSize)
                        {
                            if (A + X < Input.Count && B + Y < Input[X].Count)
                            {
                                AvgVal = Input[X + A][Y + B];
                            }


                            B++;
                        }

                        A++;
                    }

                    AvgVal = Input[X][Y];

                    A = 0;
                    while (A < KernelSize)
                    {
                        B = 0;
                        while (B < KernelSize)
                        {
                            if (A + X < Input.Count && B + Y < Input[X].Count)
                            {
                                RetVal[X + A][Y + B] = (AvgVal);

                            }

                            B++;
                        }
                        A++;
                    }

                    Y += KernelSize;
                }



                X += KernelSize;
            }

            return RetVal;
        }

        public List<List<double>> PoolFeature(List<List<double>> Input, int KernelSize)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            int A = 0;
            int B = 0;
            double MaxVal = 0;
            double AvgVal = 0;
            List<List<double>> RetVal = new List<List<double>>();
            List<double> TempVals = new List<double>();
            List<List<List<double>>> FinalRetVal = new List<List<List<double>>>();

            RetVal = this.CopyFeatures(Input);

            X = 0;
            while (X < Input.Count)
            {
                TempVals = new List<double>();
                Y = 0;
                while (Y < Input[X].Count)
                {
                    AvgVal = 0;
                    MaxVal = Input[X][Y];
                    A = 0;
                    while (A < KernelSize)
                    {
                        B = 0;
                        while (B < KernelSize)
                        {
                            if (A + X < Input.Count && B + Y < Input[X].Count)
                            {
                                if (Math.Abs(Input[X + A][Y + B]) > Math.Abs(MaxVal))
                                {
                                    MaxVal = Input[X + A][Y + B];
                                }
                            }


                            B++;
                        }

                        A++;
                    }

                    A = 0;
                    while(A < KernelSize)
                    {
                        B = 0;
                        while (B < KernelSize)
                        {
                            if (A + X < Input.Count && B + Y < Input[X].Count)
                            {
                                if (Input[X + A][Y + B] == MaxVal)
                                {
                                    RetVal[X + A][Y+B] =(MaxVal);
                                }
                                else
                                {
                                    RetVal[X + A][Y+B] =(0);
                                }
                            }

                            B++;
                        }
                        A++;
                    }

                    Y += KernelSize;
                }

                

                X += KernelSize;
            }

            return RetVal;
        }

        public List<List<List<double>>> PoolLayer(List<List<List<double>>> Input,int LayerID,int KernelSize,bool AvgLayer)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            int A = 0;
            int B = 0;
            double MaxVal = 0;
            double AvgVal = 0;
            double TempVal = 0;
            int Counter = 0;
            List<List<double>> RetVal = new List<List<double>>();
            List<double> TempVals = new List<double>();
            List<List<List<double>>> FinalRetVal = new List<List<List<double>>>();
            List<double> MaxList1 = new List<double>();
            List<List<double>> MaxList2 = new List<List<double>>();
            int YLimit = 0;
            int ZLimit = 0;

            FinalRetVal = new List<List<List<double>>>();

            Z = 0;
            while (Z < Input.Count)
            {
                MaxList2 = new List<List<double>>();
                RetVal = new List<List<double>>();
                X = 0;
                while (X < (Input[Z].Count-KernelSize+1))
                {
                    TempVals = new List<double>();
                    MaxList1 = new List<double>();
                    Y = 0;
                    while (Y < (Input[Z][X].Count-KernelSize+1))
                    {
                        AvgVal = 0;
                        Counter = 0;
                        MaxVal = Input[Z][X][Y];
                        A = 0;
                        while (A < KernelSize)
                        {
                            B = 0;
                            while (B < KernelSize)
                            {
                                if (A + X < Input[Z].Count && B + Y < Input[Z][X+A].Count)
                                {
                                    AvgVal += Input[Z][X + A][Y + B];

                                    if (Input[Z][X + A][Y + B] > MaxVal)
                                    {
                                        MaxVal = Input[Z][X + A][Y + B];
                                    }

                                    Counter++;
                                }
                                else
                                {
                                    break;
                                }


                                B++;
                            }

                            A++;
                        }
                        
                        A = 0;
                        while (A < KernelSize)
                        {
                            B = 0;
                            while (B < KernelSize)
                            {
                                if (A + X < this.MaxPoolGradients[LayerID][Z][0].Count && B + Y < this.MaxPoolGradients[LayerID][Z][0].Count)
                                {
                                    if (Input[Z][X + A][Y + B] == MaxVal)
                                    {
                                        this.MaxPoolGradients[LayerID][Z][X + A][Y + B] = 1;
                                        
                                    }
                                    else
                                    {
                                        this.MaxPoolGradients[LayerID][Z][X + A][Y + B] = 0;
                                    }
                                }
                                else
                                {
                                    break;
                                }


                                B++;
                            }

                            A++;
                        }

                        AvgVal /= (Counter);

                        if (AvgLayer)
                        {
                            TempVals.Add(AvgVal);
                        }
                        else
                        {
                            TempVals.Add(MaxVal);
                        }

                        Y+=KernelSize;
                    }

                    RetVal.Add(TempVals);

                    X+=KernelSize;
                }

                FinalRetVal.Add(RetVal);

                Z++;
            }

            return FinalRetVal;
        }

        public List<List<List<double>>> ActivateConvolutions(List<List<List<double>>> Input,int ActivationID)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            List<List<List<double>>> Output = new List<List<List<double>>>();
            List<List<double>> TempList2 = new List<List<double>>();
            List<double> TempList = new List<double>();

            while (X < Input.Count)
            {
                TempList2 = new List<List<double>>();
                Y = 0;
                while (Y < Input[X].Count)
                {
                    TempList = new List<double>();
                    Z = 0;
                    while (Z < Input[X][Y].Count)
                    {
                        switch (ActivationID)
                        {
                            case 0:
                                TempList.Add(this.NeuralNetwork.ActivationFunction(Input[X][Y][Z], 0));
                                break;

                            case 1:
                                TempList.Add(this.NeuralNetwork.ActivationFunction(Input[X][Y][Z], 1));
                                break;

                            case 2:
                                TempList.Add(this.NeuralNetwork.ActivationFunction(Input[X][Y][Z], 2));
                                break;
                            case 3:
                                TempList.Add(this.NeuralNetwork.ActivationFunction(Input[X][Y][Z], 3));
                                break;
                        }

                        Z++;
                    }

                    TempList2.Add(TempList);

                    Y++;
                }

                Output.Add(TempList2);

                X++;
            }


            return Output;
        }

        //public List<List<List<double>>>

        public List<List<List<double>>> ActivateDerivativeConvolutions(List<List<List<double>>> Input, int ActivationID)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            List<List<List<double>>> Output = new List<List<List<double>>>();
            List<List<double>> TempList2 = new List<List<double>>();
            List<double> TempList = new List<double>();

            while(X < Input.Count)
            {
                TempList2 = new List<List<double>>();
                Y = 0;
                while(Y < Input[X].Count)
                {
                    TempList = new List<double>();
                    Z = 0;
                    while(Z < Input[X][Y].Count)
                    {
                        switch(ActivationID)
                        {
                            case 0:
                                TempList.Add(this.NeuralNetwork.ActivationFunctionDerivative(Input[X][Y][Z], 0));
                                break;

                            case 1:
                                TempList.Add(this.NeuralNetwork.ActivationFunctionDerivative(Input[X][Y][Z], 1));
                                break;

                            case 2:
                                TempList.Add(this.NeuralNetwork.ActivationFunctionDerivative(Input[X][Y][Z], 2));
                                break;
                            case 3:
                                TempList.Add(this.NeuralNetwork.ActivationFunctionDerivative(Input[X][Y][Z], 3));

                                if (double.IsNaN(TempList[TempList.Count - 1]))
                                {
                                    break;
                                }
                                break;
                        }

                        Z++;
                    }

                    TempList2.Add(TempList);

                    Y++;
                }

                Output.Add(TempList2);

                X++;
            }


            return Output;
        }

        public List<List<List<double>>> FullConvolve(List<List<List<double>>> Features, List<List<List<double>>> FilterList, int Stride, int TargetMapCount = -1)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            int ZZ = 0;
            int A = 0;
            int B = 0;
            int C = 0;
            int D = 0;
            double TempVal = 0;
            double TempVal2 = 0;
            List<double> TempList = new List<double>();
            List<List<double>> TempList2 = new List<List<double>>();
            List<List<double>> SummedMap = new List<List<double>>();
            List<List<List<double>>> TempList3 = new List<List<List<double>>>();
            int Counter = 0;

            while (X < FilterList.Count)
            {
                SummedMap = new List<List<double>>();
                Y = 0;
                while (Y < Features.Count)
                {
                    TempList2 = new List<List<double>>();
                    C = 0;
                    while (C < Features[Y].Count)
                    {
                        TempList = new List<double>();
                        D = 0;
                        while (D < Features[Y][C].Count)
                        {
                            Counter = 0;
                            TempVal = 0;
                            A = 0;
                            while (A < FilterList[X].Count)
                            {
                                B = 0;
                                while (B < FilterList[X][A].Count)
                                {
                                    if (C + A < Features[Y].Count && D + B < Features[Y].Count)
                                    {
                                        TempVal2 = (FilterList[X][A][B] * Features[Y][C + A][D + B]);

                                        Counter++;
                                        TempVal += TempVal2;
                                    }


                                    B++;
                                }

                                A++;
                            }

                            //TempVal = Math.Tanh(TempVal);

                            TempList.Add(TempVal);

                            D += Stride;
                        }

                        TempList2.Add(TempList);

                        C += Stride;
                    }

                    if (Y == 0)
                    {
                        SummedMap = TempList2;
                    }
                    else
                    {
                        SummedMap = this.ElementWiseSummation(TempList2, SummedMap);
                    }


                    Y++;
                }

                TempList3.Add(SummedMap);

                X++;
            }

            return TempList3;
        }

        public List<List<List<double>>> Convolve(List<List<List<double>>> Features, List<List<List<double>>> FilterList, int Stride, bool RotateFilters)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            int ZZ = 0;
            int A = 0;
            int B = 0;
            int C = 0;
            int D = 0;
            double TempVal = 0;
            double TempVal2 = 0;
            List<double> TempList = new List<double>();
            List<List<double>> TempList2 = new List<List<double>>();
            List<List<double>> SummedMap = new List<List<double>>();
            List<List<List<double>>> TempList3 = new List<List<List<double>>>();
            List<List<List<double>>> RotatedFilterList = new List<List<List<double>>>();
            int Counter = 0;

            if(RotateFilters)
            {
                X = 0;
                while (X < FilterList.Count)
                {
                    RotatedFilterList.Add(this.Rotate2DMatrix180(FilterList[X]));

                    X++;
                }
            }
            else
            {
                RotatedFilterList = FilterList;
            }
            

            X = 0;
            while (X < RotatedFilterList.Count)
            {
                SummedMap = new List<List<double>>();
                Y = 0;
                while (Y < Features.Count)
                {
                    TempList2 = new List<List<double>>();
                    C = 0;
                    while (C < Features[Y].Count - (RotatedFilterList[X].Count) + 1)
                    {
                        TempList = new List<double>();
                        D = 0;
                        while (D < Features[Y][C].Count - (RotatedFilterList[X].Count) + 1)
                        {
                            Counter = 0;
                            TempVal = 0;
                            A = 0;
                            while (A < RotatedFilterList[X].Count)
                            {
                                B = 0;
                                while (B < RotatedFilterList[X][A].Count)
                                {

                                    TempVal2 = (RotatedFilterList[X][A][B] * Features[Y][C + A][D + B]);

                                    Counter++;
                                    TempVal += TempVal2;



                                    B++;
                                }

                                A++;
                            }

                            //TempVal = Math.Tanh(TempVal);

                            TempList.Add(TempVal);

                            D+=Stride;
                        }

                        TempList2.Add(TempList);

                        C+=Stride;
                    }

                    if(Y == 0)
                    {
                        SummedMap = TempList2;
                    }
                    else
                    {
                        SummedMap = this.ElementWiseSummation(TempList2, SummedMap);
                    }
                    

                    Y++;
                }

                TempList3.Add(SummedMap);

                X++;
            }

            return TempList3;
        }

        public List<List<List<double>>> FullConvolve(List<List<List<double>>> Features, List<List<List<double>>> FilterList, int Stride, bool RotateFilters)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            int ZZ = 0;
            int A = 0;
            int B = 0;
            int C = 0;
            int D = 0;
            double TempVal = 0;
            double TempVal2 = 0;
            List<double> TempList = new List<double>();
            List<List<double>> TempList2 = new List<List<double>>();
            List<List<double>> SummedMap = new List<List<double>>();
            List<List<List<double>>> TempList3 = new List<List<List<double>>>();
            List<List<List<double>>> RotatedFilterList = new List<List<List<double>>>();
            int Counter = 0;

            if (RotateFilters)
            {
                X = 0;
                while (X < FilterList.Count)
                {
                    RotatedFilterList.Add(this.Rotate2DMatrix180(FilterList[X]));

                    X++;
                }
            }
            else
            {
                RotatedFilterList = FilterList;
            }


            X = 0;
            while (X < RotatedFilterList.Count)
            {
                SummedMap = new List<List<double>>();
                Y = 0;
                while (Y < Features.Count)
                {
                    TempList2 = new List<List<double>>();
                    C = 0;
                    while (C < Features[Y].Count)
                    {
                        TempList = new List<double>();
                        D = 0;
                        while (D < Features[Y][C].Count)
                        {
                            Counter = 0;
                            TempVal = 0;
                            A = 0;
                            while (A < RotatedFilterList[X].Count)
                            {
                                B = 0;
                                while (B < RotatedFilterList[X][A].Count)
                                {
                                    if(C+A < Features[Y].Count && D + B < Features[Y].Count)
                                    {
                                        TempVal2 = (RotatedFilterList[X][A][B] * Features[Y][C + A][D + B]);
                                    }
                                    else
                                    {
                                        TempVal2 = 0;
                                    }
                                    

                                    Counter++;
                                    TempVal += TempVal2;



                                    B++;
                                }

                                A++;
                            }

                            //TempVal = Math.Tanh(TempVal);

                            TempList.Add(TempVal);

                            D += Stride;
                        }

                        TempList2.Add(TempList);

                        C += Stride;
                    }

                    if (Y == 0)
                    {
                        SummedMap = TempList2;
                    }
                    else
                    {
                        SummedMap = this.ElementWiseSummation(TempList2, SummedMap);
                    }


                    Y++;
                }

                TempList3.Add(SummedMap);

                X++;
            }

            return TempList3;
        }

        public double ELU(double Input)
        {
            if(Input >= 0)
            {
                return Input;
            }
            else
            {
                return Math.Pow(Math.E, Input - 1);
            }
        }


        public List<List<List<double>>> DeConvolve(List<List<List<double>>> Features, List<List<List<double>>> FilterList, int Stride,int Padding)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            int ZZ = 0;
            int A = 0;
            int B = 0;
            int C = 0;
            int D = 0;
            int E = 0;
            int F = 0;
            int U = 0;
            int V = 0;
            double TempVal = 0;
            double TempVal2 = 0;
            List<double> TempList = new List<double>();
            List<List<double>> TempList2 = new List<List<double>>();
            List<List<double>> SummedMap = new List<List<double>>();
            List<List<List<double>>> TempList3 = new List<List<List<double>>>();
            List<List<List<double>>> RotatedFilterList = new List<List<List<double>>>();
            int Counter = 0;

            X = 0;
            while (X < FilterList.Count)
            {
                RotatedFilterList.Add(this.Rotate2DMatrix180(FilterList[X]));

                X++;
            }

            U = 0;
            while(U < FilterList.Count)
            {
                SummedMap = new List<List<double>>();

                V = 0;
                while(V < Features.Count)
                {
                    TempList2 = new List<List<double>>();
                    TempList2 = CreateEmptyMap(Features[V].Count + Padding);
                    X = 0;
                    while (X < Features[V].Count - FilterList[U].Count + 1)
                    {
                        Y = 0;
                        while (Y < Features[V][0].Count - FilterList[U][0].Count + 1)
                        {
                            A = 0;
                            while (A < FilterList[U].Count)
                            {
                                B = 0;
                                while (B < FilterList[U][A].Count)
                                {
                                    TempList2[X + A][Y + B] += (Features[V][X][Y] * FilterList[U][A][B]);

                                    B++;
                                }

                                A++;
                            }

                            Y++;
                        }

                        X++;
                    }

                    if (V == 0)
                    {
                        SummedMap = TempList2;
                    }
                    else
                    {
                        SummedMap = this.ElementWiseSummation(TempList2, SummedMap);
                    }

                    V++;
                }

                TempList3.Add(SummedMap);

                U++;
            }


            return TempList3;
        }

        List<List<double>> CreateEmptyMap(int Dimensions,double InitializationVal = 0)
        {
            List<double> SubOutput = new List<double>();
            List<List<double>> Output = new List<List<double>>();
            int X = 0;
            int Y = 0;

            while(X < Dimensions)
            {
                SubOutput = new List<double>();
                Y = 0;
                while(Y < Dimensions)
                {
                    SubOutput.Add(InitializationVal);

                    Y++;
                }

                Output.Add(SubOutput);

                X++;
            }

            return Output;
        }




        public List<List<List<double>>> PoolMaps(List<List<List<double>>> Activations, int KernelSize = 2)
        {
            List<List<List<double>>> RetVal = new List<List<List<double>>>();
            List<List<double>> TempList2 = new List<List<double>>();
            List<double> TempList = new List<double>();
            int X = 0;
            int Y = 0;
            int Z = 0;
            int A = 0;
            int B = 0;
            int C = 0;
            double MaxVal = Activations[0][0][0];
            double AvgVal = 0;

            while(X < Activations.Count)
            {
                TempList2 = new List<List<double>>();
                AvgVal = 0;
                Y = 0;
                while( Y < Activations[X].Count - KernelSize)
                {
                    TempList = new List<double>();
                    Z = 0;
                    while(Z < Activations[X][Y].Count - KernelSize)
                    {
                        A = 0;
                        AvgVal = 0;
                        while(A < KernelSize)
                        {
                            B = 0;
                            while(B < KernelSize)
                            {
                                AvgVal += Activations[X][Y + A][Z + B];

                                B++;
                            }

                            A++;
                        }

                        TempList.Add(AvgVal / (KernelSize * KernelSize));

                        Z +=KernelSize;
                    }

                    TempList2.Add(TempList);

                    Y +=KernelSize;
                }

                RetVal.Add(TempList2);

                X++;
            }

            

            return RetVal;
        }

        
        public List<double> ConcatVectors(List<double> Input1,List<double> Input2)
        {
            List<double> RetVal = new List<double>();
            int X = 0;

            while(X < Input1.Count)
            {
                RetVal.Add(Input1[X]);

                X++;
            }

            X = 0;
            while(X < Input2.Count)
            {
                RetVal.Add(Input2[X]);

                X++;
            }

            return RetVal;
        }

        public List<double> Flatten3DVector(List<List<List<double>>> Input)
        {
            //Normal: 2x63x63
            int X = 0;
            int Y = 0;
            int Z = 0;
            List<double> RetVal = new List<double>();

            while(X < Input.Count)
            {
                Y = 0;
                while (Y < Input[X].Count)
                {
                    Z = 0;
                    while(Z < Input[X][Y].Count)
                    {
                        RetVal.Add(Input[X][Y][Z]);

                        Z++;
                    }

                    Y++;
                }

                X++;
            }

            return RetVal;
        }

        public List<double> Flatten2DVector(List<List<double>> Input)
        {
            int X = 0;
            int Y = 0;
            List<double> Output = new List<double>();

            while(X < Input.Count)
            {
                Y = 0;
                while(Y < Input[X].Count)
                {
                    Output.Add(Input[X][Y]);

                    Y++;
                }

                X++;
            }

            return Output;
        }

        public List<List<double>> Rotate2DMatrix180(List<List<double>> Inputs)
        {
            List<List<double>> Outputs = new List<List<double>>();
            List<double> TempList = new List<double>();
            int X = 0;
            int Y = 0;
            
            while(X < Inputs.Count)
            {
                TempList = new List<double>();
                Y = 0;
                while(Y < Inputs[X].Count)
                {
                    TempList.Add(Inputs[Inputs.Count - 1 - X][Inputs[X].Count - 1 - Y]);

                    Y++;
                }

                Outputs.Add(TempList);

                X++;
            }
            
            return Outputs;
        }

        public Bitmap ArrayToBMP(List<List<double>> Input,double ScaleConst = 255)
        {
            int ImageDim = Input.Count;
            Bitmap RetVal = new Bitmap(Input[0].Count, Input.Count);
            int X = 0;
            int Y = 0;
            int RGB = 0;
            int RVal = 0;
            int GVal = 0;
            int BVal = 0;
            int NewX = 0;
            int NewY = 0;
            double TempVal = 0;
            double MinVal = Input[0][0];

            X = 0;
            while (X < Input.Count)
            {
                Y = 0;
                while(Y < Input[X].Count)
                {
                    RVal = Math.Max(0, Math.Min(255, (int)(Math.Abs(Input[X][Y] * ScaleConst ))));
                    GVal = Math.Max(0, Math.Min(255, (int)(Math.Abs(Input[X][Y] * ScaleConst))));
                    BVal = Math.Max(0, Math.Min(255, (int)(Math.Abs(Input[X][Y] * ScaleConst ))));

                    RGB = RVal;

                    if(X < Input.Count && Y < Input[X].Count)
                    {
                        RetVal.SetPixel(Y, X, Color.FromArgb(RGB, RGB, RGB));
                    }
                    

                    Y++;
                }
                
               
                X++;
            }


            //Debug.Print(MinVal.ToString() + " - " + this.NeuralNetwork.MeanSquaredError.ToString());

            return RetVal;
        }

        public Bitmap ArrayToBMPTanH(List<List<double>> Input)
        {
            int ImageDim = Input.Count;
            Bitmap RetVal = new Bitmap(ImageDim, ImageDim);
            int X = 0;
            int Y = 0;
            int RGB = 0;
            int RVal = 0;
            int GVal = 0;
            int BVal = 0;
            int NewX = 0;
            int NewY = 0;
            double TempVal = 0;
            double MinVal = Input[0][0];

            //Input = this.NormalizeDataSet(Input);

            X = 0;
            while (X < Input.Count)
            {
                Y = 0;
                while (Y < Input[X].Count)
                {
                    TempVal = Input[X][Y] + 1.0f;
                    TempVal = (TempVal / 2.0f);
                    TempVal *= 255;
                    RGB = (int)TempVal;

                    RGB = Math.Min(Math.Max(RGB, 0), 255);

                    RetVal.SetPixel(Y, X, Color.FromArgb(RGB, RGB, RGB));

                    Y++;
                }


                X++;
            }


            //Debug.Print(MinVal.ToString() + " - " + this.NeuralNetwork.MeanSquaredError.ToString());

            return RetVal;
        }

        public List<List<double>> BMPToArrayColor(Bitmap Input)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            List<double> TempRow = new List<double>();
            List<List<double>> TempRow2 = new List<List<double>>();
            List<List<double>> RetVal = new List<List<double>>();

            Input = new Bitmap(Input, this.ImageDimensions, this.ImageDimensions);

            X = 0;
            TempRow2 = new List<List<double>>();
            while (X < Input.Height)
            {
                Y = 0;
                TempRow = new List<double>();
                while (Y < Input.Width)
                {
                    //TempRow.Add(((((Input.GetPixel(Y, X).R + Input.GetPixel(Y, X).G + Input.GetPixel(Y, X).B) / 3) * 0.001)));
                    TempRow.Add(Input.GetPixel(Y, X).R * 0.001);
                    TempRow.Add(Input.GetPixel(Y, X).G * 0.001);
                    TempRow.Add(Input.GetPixel(Y, X).B * 0.001);


                    Y++;
                }

                RetVal.Add(TempRow);

                X++;
            }

            return RetVal;
        }


        public List<List<List<double>>> BMPToArray(Bitmap Input)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            double TempVal = 0;
            List<double> TempRow = new List<double>();
            List<List<double>> TempRow2 = new List<List<double>>();
            List<List<double>> RetVal = new List<List<double>>();
            List<List<List<double>>> FinalRetVal = new List<List<List<double>>>();

            Input = new Bitmap(Input, this.ImageDimensions, this.ImageDimensions);

            X = 0;
            TempRow2 = new List<List<double>>();
            while (X < Input.Height)
            {
                Y = 0;
                TempRow = new List<double>();
                while (Y < Input.Width)
                {
                    //TempVal = (Input.GetPixel(Y, X).R + Input.GetPixel(Y, X).G + Input.GetPixel(Y, X).B) / 3.0f * 0.001f;
                    TempVal = (Input.GetPixel(Y, X).R + Input.GetPixel(Y, X).G + Input.GetPixel(Y, X).B) / 3.0f / 255.0f;
                    TempVal = TempVal * 2.0f - 1.0f;
                    TempRow.Add(TempVal);

                    Y++;
                }

                RetVal.Add(TempRow);

                X++;
            }

            FinalRetVal.Add(RetVal);

            return FinalRetVal;
        }

        public double ReLU(double Input,bool LeakyReLU)
        {
            double TempVal = 0;

            if(LeakyReLU)
            {                
                if (Input > 0)
                {
                    TempVal = Input;
                }
                else
                {
                    TempVal = Input * this.NeuralNetwork.ReLUConst;
                }
            }
            else
            {
                if (Input > 0)
                {
                    TempVal = Input;
                }
                else
                {
                    TempVal = 0;
                }
            }
            

            return TempVal;
        }

        public double Sigmoid(double Input)
        {
            return 1 / (1 + Math.Pow(Math.E, -1 * Input));
        }
    }
}
