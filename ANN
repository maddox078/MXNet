using Microsoft.VisualBasic.ApplicationServices;
using Microsoft.VisualBasic.Logging;
using System;
using System.Collections.Generic;
using System.Diagnostics;
using System.Linq;
using System.Runtime.InteropServices;
using System.Text;
using System.Windows.Forms.VisualStyles;

namespace MaddoxNET
{
    public class ANN_Perf
    {
        public double[][][] Weights = new double [0][][];
        public double [][][] WeightDeltas = new double[0][][];
        public double [][][] PrevWeights = new double [0][][];
        public double [][][] PrevWeightsM = new double[0][][];
        public double [][][] PrevWeightsV = new double [0][][];
        public double [][] Activations = new double[0][];
        public double [][] NetInputs = new double[0][];
        public double [][] Errors = new double[0][];
        public int [] ActivationFunctions = new int[0];
        public double [][] BatchNormPopStats = new double[0][];
        public double LearningRate = 0;
        public double Momentum = 0;
        public double ReLUConst = 0.01;
        public double RMSPropConst = 0.9;
        public double MeanSquaredError = 0;
        public double B1 = 0.5;
        public double B2 = 0.999;
        public double WeightClipFactor = 0.0001;
        public List<double> NormalizationConsts = new List<double>();


        public ANN_Perf(int [] LayerCounts,int [] ActivationFunctions,int LossFunction,double LearningRate,double MomentumFactor,int WeightInitializationID = 0)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            double [] LayerActivations;
            double[] LayerNetInputs;
            double[] LayerError;
            double [][] LayerWeights;
            double [] NeuronWeights;
            double [][] PrevLayerWeightsM;
            double [][] PrevLayerWeightsV;
            double [][] PrevLayerWeights;
            double [] PrevNeuronWeightsM;
            double [] PrevNeuronWeightsV;
            double [] PrevNeuronWeights;
            Random Rnd = new Random(System.Guid.NewGuid().GetHashCode());
            double U1 = Rnd.NextDouble();
            double U2 = Rnd.NextDouble();
            double Z1 = Math.Sqrt(-2.0f * Math.Log(U1)) * Math.Cos(2.0f * Math.PI * U2);
            double Z2 = Math.Sqrt(-2.0f * Math.Log(U1)) * Math.Sin(2.0f * Math.PI * U2);
            double StdDev = 0.005;
            double TempVal = 0;


            this.Weights = new double[LayerCounts.Length][][];
            this.WeightDeltas = new double[LayerCounts.Length][][]; 
            this.PrevWeights = new double[LayerCounts.Length][][];
            this.PrevWeightsM = new double[LayerCounts.Length][][];
            this.PrevWeightsV = new double[LayerCounts.Length][][];
            this.Activations = new double[LayerCounts.Length][];
            this.NetInputs = new double[LayerCounts.Length][];
            this.Errors = new double[LayerCounts.Length][];

            this.ActivationFunctions = ActivationFunctions;
            this.LearningRate = LearningRate;
            this.Momentum = MomentumFactor;

            //Layer
            while(X < LayerCounts.Length)
            {
                //Neuron
                PrevLayerWeightsM = new double[LayerCounts[X]][];
                PrevLayerWeightsV = new double[LayerCounts[X]][];
                PrevLayerWeights = new double[LayerCounts[X]][];
                LayerWeights = new double[LayerCounts[X]][];
                LayerActivations = new double[LayerCounts[X]];
                LayerNetInputs = new double[LayerCounts[X]];
                LayerError = new double[LayerCounts[X]];
                Rnd = new Random(System.Guid.NewGuid().GetHashCode());
                Y = 0;
                while(Y < LayerCounts[X])
                {
                    LayerActivations[Y] = Rnd.NextDouble();
                    LayerNetInputs[Y] = 0;
                    LayerError[Y] = 0;

                    NeuronWeights = new double[LayerCounts[Math.Max(0, X - 1)]];
                    PrevNeuronWeightsM = new double[LayerCounts[Math.Max(0, X - 1)]];
                    PrevNeuronWeightsV = new double[LayerCounts[Math.Max(0, X - 1)]];
                    PrevNeuronWeights = new double[LayerCounts[Math.Max(0, X - 1)]];

                    //Dendrite
                    Z = 0;
                    while(Z < LayerCounts[Math.Max(0,X-1)])
                    {
                        U1 = Rnd.NextDouble();
                        U2 = Rnd.NextDouble();
                        Z1 = Math.Sqrt(-2.0f * Math.Log(U1)) * Math.Cos(2.0f * Math.PI * U2);

                        if (Rnd.Next() % 3 == 0)
                        {
                            TempVal =  (Rnd.NextDouble() * (0.009 - 0.001) + 0.001) * -1;
                        }
                        else
                        {
                            TempVal = Rnd.NextDouble() * (0.009 - 0.001) + 0.001;
                        }


                        NeuronWeights[Z] = TempVal;




                        PrevNeuronWeightsM[Z] = 0;
                        PrevNeuronWeightsV[Z] = 0;
                        PrevNeuronWeights[Z] =0;

                        Z++;
                    }



                    LayerWeights[Y] = NeuronWeights;
                    PrevLayerWeightsM[Y] = PrevNeuronWeightsM;
                    PrevLayerWeightsV[Y] = PrevNeuronWeightsV;
                    PrevLayerWeights[Y] = PrevNeuronWeights;

                    Y++;
                }

                this.Activations[X] = LayerActivations;
                this.NetInputs[X] = LayerNetInputs;
                this.Errors[X] = LayerError;
                this.PrevWeightsV[X] = PrevLayerWeightsV;
                this.PrevWeightsM[X] = PrevLayerWeightsM;
                this.Weights[X] = LayerWeights;
                this.WeightDeltas[X] = PrevLayerWeights;
                this.PrevWeights[X] = PrevLayerWeights;

                X++;
            }

            switch(WeightInitializationID)
            {
                case 0:

                    break;

                case 1:
                    XavierInitialize();
                    break;

                case 2:
                    HeInitialize();
                    break;

            }
            //XavierInitialize();
            //HeInitialize();
        }

        public void XavierInitialize()
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            double Upper = 0;
            double Lower = 0;
            double Variance = 0;
            Random Rnd = new Random(System.Guid.NewGuid().GetHashCode());

            while (X < this.Weights.Length)
            {
                Upper = this.Activations[X].Length;
                Lower = this.Activations[Math.Max(0, X - 1)].Length;
                
                Y = 0;
                while(Y < this.Weights[X].Length)
                {
                    Z = 0;
                    while (Z < this.Weights[X][Y].Length)
                    {
                        Variance = 2.0f / (Upper+Lower);
                        this.Weights[X][Y][Z] = Rnd.Next((int)(Math.Min(Upper,Lower)),(int)(Math.Max(Lower,Upper))) *  Math.Sqrt(Variance);

                        Z++;
                    }

                    Y++;
                }

                X++;
            }
        }

        public double RandDoubleInRange(double Lower, double Upper)
        {
            Random Rnd = new Random(System.Guid.NewGuid().GetHashCode());

            if (Rnd.Next() % 2 == 0)
            {
                return (Rnd.NextDouble() * (Upper - Lower) + Lower) * -1;
            }
            else
            {
                return Rnd.NextDouble() * (Upper - Lower) + Lower;
            }


        }

        public void HeInitialize()
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            double StdDev = 0;
            Random Rnd = new Random(System.Guid.NewGuid().GetHashCode());
            int InputCount = 0;
            int OutputCount = 0;

            while(X < this.Weights.Length)
            {
                StdDev = Math.Sqrt(2.0f / this.Activations[Math.Max(X-1, 0)].Length);
                InputCount = this.Activations[Math.Max(X - 1, 0)].Length;
                OutputCount = this.Activations[X].Length;

                Y = 0;
                while(Y < this.Weights[X].Length)
                {
                    Z = 0;
                    while(Z < this.Weights[X][Y].Length)
                    {
                        this.Weights[X][Y][Z] = Rnd.Next(Math.Min(InputCount,OutputCount),Math.Max(InputCount,OutputCount)) * StdDev;

                        Z++;
                    }
                    
                    Y++;
                }

                X++;
            }
        }

        public List<List<double>> NormalizeDataSet(List<List<double>> Inputs)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            double Mean = 0;
            double StdDev = 0;

            while (X < Inputs.Count)
            {
                Y = 0;
                while (Y < Inputs[X].Count)
                {
                    Mean += Inputs[X][Y];


                    Y++;
                }

                X++;
            }

            Mean /= (X * Y);
            StdDev = CalculateStandardDeviation(Inputs, Mean);

            X = 0;
            while (X < Inputs.Count)
            {
                Y = 0;
                while (Y < Inputs[X].Count)
                {
                    Inputs[X][Y] = (Inputs[X][Y] - Mean) / Math.Sqrt(StdDev);

                    Y++;
                }

                X++;
            }

            return Inputs;
        }

        public double GetTotalError()
        {
            int X = 0;
            double RetVal = 0;

            while(X < this.Errors[this.Errors.Length - 1].Length)
            {
                RetVal += this.Errors[this.Errors.Length - 1][X];
                
                X++;
            }

            return RetVal;
        }

        public void Infer(List<double> Inputs)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;

            while(X < this.Activations.Length)
            {
                Y = 0;
                while(Y < this.Activations[X].Length)
                {
                    this.Activations[X][Y] = this.Activations[X][Y] * this.BatchNormPopStats[X][1] + this.BatchNormPopStats[X][0];

                    Y++;
                }

                X++;
            }
        }

        public List<double> ResolveJacobian(List<List<double>> InputDerivative,List<double> LossVector)
        {
            List<double> RetVal = new List<double>();
            int X = 0;
            int Y = 0;

            while(X < InputDerivative.Count)
            {
                RetVal.Add(0);

                X++;
            }

            X = 0;
            while(X < LossVector.Count)
            {
                Y = 0;
                while(Y < LossVector.Count)
                {
                    RetVal[X] += (LossVector[Y] * InputDerivative[Y][X]);

                    Y++;
                }

                X++;
            }


            return RetVal;
        }


        public List<List<double>> SoftmaxDerivative(List<double> SoftmaxInputs)
        {
            List<double> SubRetVal = new List<double>();
            List<List<double>> RetVal = new List<List<double>>();
            int X = 0;
            int Y = 0;

            while(X < SoftmaxInputs.Count)
            {
                SubRetVal = new List<double>();
                Y = 0;
                while(Y < SoftmaxInputs.Count)
                {
                    if(X == Y)
                    {
                        SubRetVal.Add(SoftmaxInputs[X] * (1.0f - SoftmaxInputs[X]));
                    }
                    else
                    {
                        SubRetVal.Add(-SoftmaxInputs[X] * SoftmaxInputs[Y]);
                    }
                    

                    Y++;
                }

                RetVal.Add(SubRetVal);

                X++;
            }

            return RetVal;
        }

        public void ForwardPropagate(double[] Inputs,int OutputNormalizationMethod,bool NormalizeOutputLayer = true)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            double NetSignal = 0;
            double[] TempList = new double[0];
            int Limit = 0;

            Limit = Math.Abs(Inputs.Length - this.Activations[0].Length);

            X = 0;
            while(X < Limit)
            {
                Debug.Print("MISMATCH");

                X++;
            }

            X = 0;
            while(X < this.Activations[0].Length)
            {
                    this.NetInputs[0][X] = Inputs[X];


                //this.Activations[0][X] = this.ActivationFunction(Inputs[X], this.ActivationFunctions[0]);
                //this.Activations[0][X] = Inputs[X];

                X++;
            }

            //this.NetInputs[0] = this.NormalizeDataSet(this.NetInputs[0], 3);

            X = 0;
            while(X < this.Activations[0].Length)
            {
                this.Activations[0][X] = this.ActivationFunction(this.NetInputs[0][X], this.ActivationFunctions[0]);

                if (double.IsNaN(this.Activations[0][X]))
                {
                    break;
                }

                X++;
            }

            //this.Activations[0] = this.NormalizeDataSet(this.Activations[0], 3);

            X = 1;
            while(X < this.Activations.Length)
            {
                Y = 0;
                while(Y < this.Activations[X].Length)
                {
                    TempList = this.Activations[X - 1];
                    NetSignal = 0;
                    Z = 0;
                    while(Z < TempList.Length)
                    {
                        NetSignal += (this.Weights[X][Y][Z] * TempList[Z]);

                        if (double.IsNaN(NetSignal))
                        {
                            break;
                        }

                        Z++;
                    }

                    //NetSignal /= Z;

                    this.NetInputs[X][Y] = NetSignal;

                    Y++;
                }

                //if (X == this.Activations.Count - 1)
                //{
                //    if (NormalizeOutputLayer == true)
                //    {
                //        this.NetInputs[X] = this.NormalizeDataSet(this.NetInputs[X], 3);
                //    }
                //}
                //else
                //{
                //    this.NetInputs[X] = this.NormalizeDataSet(this.NetInputs[X], 3);
                //}

                Y = 0;
                while(Y < this.Activations[X].Length)
                {
                    this.Activations[X][Y] = this.ActivationFunction(this.NetInputs[X][Y], this.ActivationFunctions[X]);

                    if (double.IsNaN(this.Activations[X][Y]))
                    {
                        break;
                    }

                    Y++;
                }

                //if (X == this.Activations.Count - 1)
                //{
                //    if (NormalizeOutputLayer == true)
                //    {
                //        this.Activations[X] = this.NormalizeDataSet(this.Activations[X], 3);
                //    }
                //}
                //else
                //{
                //    this.Activations[X] = this.NormalizeDataSet(this.Activations[X], 3);
                //}

                X++;
            }

            if(OutputNormalizationMethod != 9)
            {
                //this.Activations[this.Activations.Length - 1] = this.NormalizeDataSet(this.Activations[this.Activations.Length - 1], OutputNormalizationMethod);
                //this.NetInputs[this.Activations.Count - 1] = this.NormalizeDataSet(this.NetInputs[this.Activations.Count - 1], OutputNormalizationMethod);
            }
            
        }

       
        public int GetActivationIndex()
        {
            int X = 0;
            int ActivationIndex = 0;
            double MaxActivation = this.Activations[1][0];

            while (X < this.Activations[this.Activations.Length - 1].Length)
            {
                if ((this.Activations[1][X]) > (MaxActivation))
                {
                    MaxActivation = this.Activations[1][X];
                    ActivationIndex = X;
                }

                X++;
            }

            return ActivationIndex;
        }

        double CalculateIntersectionOverUnion(double XA_1, double YA_1, double XA_2, double YA_2, double XB_1, double YB_1, double XB_2, double YB_2)
        {
            double RetVal = 0;
            double Intersect = 0;
            double Union = 0;
            double AreaA = 0;
            double AreaB = 0;

            AreaA = Math.Abs(XA_1 - XA_2) * Math.Abs(YA_1 - YA_2);
            AreaB = Math.Abs(XB_1 - XB_2) * Math.Abs(YB_1 - YB_2);

            Intersect = Math.Max(0, Math.Min(XA_1, XB_2) - Math.Max(XA_1, XB_1)) * Math.Max(0, Math.Min(YA_2, YB_2) - Math.Max(YA_1, YB_1));

            Union = AreaA + AreaB - Intersect;

            if(Intersect == 0)
            {
                return 0.000001;
            }

            return Intersect / Union;
        }

        public void UpdateLearningRate(int Epoch,double InitialRate,double MinimumRate)
        {
            double TempVal = 0;

            TempVal = (1 + Math.Cos((double)(Epoch / 250.0f) * Math.PI));
            TempVal = MinimumRate + 0.5f * (InitialRate - MinimumRate) * TempVal;
            this.LearningRate = TempVal;
        }

        public void FindOutlier(List<double> Inputs)
        {
            int X = 0;
            List<double> ZScores = new List<double>();

            //while(X < Inputs.Count)
            //{
            //    ZScores.Add(this.ZScore(Inputs, Inputs[X]));

            //    X++;
            //}

            //X = 0;
            //while(X < ZScores.Count)
            //{
            //    Debug.Print(ZScores[X].ToString());

            //    X++;
            //}
        }

        public void BackPropagate(double[] Inputs,double[] Outputs, int OutputNormalizationMethod, bool TrainWeights, int OptimizerID, bool OnlyError = false, bool NormalizeOutputLayer = true, double AdditionalVal = 0, double AdditionalVal2 = 0)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            int A = 0;
            int B = 0;
            double L2 = 0;
            double Delta = 0;
            double MSE = 0;
            double TempVal = 0;
            double ADAMDelta = 0;
            double RMSPropDelta = 0;
            double SGDDelta = 0;
            //List<List<List<double>>> NewWeights = this.Weights;
            //List<List<List<double>>> NewPrevWeights = this.PrevWeights;
            double[] TransposedActivations;
            double[] SoftmaxDerivatives;

            this.ForwardPropagate(Inputs, OutputNormalizationMethod, NormalizeOutputLayer);

            


            //this.PrevWeights.Clear();
            //this.WeightDeltas = this.Weights;

            ////////////////////////////

            X = 0;
            while (X < this.Activations[this.Activations.Length - 1].Length)
            {
                if (OnlyError == false)
                {
                    //L2 = (this.Activations[this.Activations.Count - 1][X] - Outputs[X]);
                    if (Outputs[X] == 0)
                    {
                        //L2 = (1.0f / (1.0f - this.Activations[this.Activations.Count - 1][X]));
                        L2 = (this.Activations[this.Activations.Length - 1][X] - Outputs[X]);


                        if (OutputNormalizationMethod != 2)
                        {
                            L2 *= this.ActivationFunctionDerivative(this.NetInputs[this.Activations.Length - 1][X], this.ActivationFunctions[this.Activations.Length - 1]);
                        }
                    }
                    else
                    {
                        //L2 = -1.0f / this.Activations[this.Activations.Count - 1][X];                        
                        L2 = (this.Activations[this.Activations.Length - 1][X] - 1.0f);

                        if (OutputNormalizationMethod != 2)
                        {
                            L2 *= this.ActivationFunctionDerivative(this.NetInputs[this.Activations.Length - 1][X], this.ActivationFunctions[this.Activations.Length - 1]);
                        }
                        //L2 = (this.Activations[this.Activations.Count - 1][X]);
                    }




                    this.Errors[this.Errors.Length - 1][X] = L2;
                }
                else
                {
                    if(X < Outputs.Length)
                    {
                        L2 = Outputs[X];
                    }
                    else
                    {
                        L2 = 1;
                    }
                    

                    
                    //L2 *= this.ActivationFunctionDerivative(AdditionalVal2, 1);
                    L2 *= this.ActivationFunctionDerivative(this.NetInputs[this.Activations.Length - 1][X], this.ActivationFunctions[this.ActivationFunctions.Length - 1]);


                    //this.Errors[this.Errors.Count - 1][X] = -(1.0f / (AdditionalVal)) * L2;
                    this.Errors[this.Errors.Length - 1][X] = L2;
                }

                if(OutputNormalizationMethod == 2)
                {
                    //SoftmaxDerivatives = ResolveJacobian(SoftmaxDerivative(this.Activations[this.Activations.Length - 1]), this.Errors[this.Errors.Length - 1]);                    
                }

                Y = 0;
                while (Y < this.Weights[this.Weights.Length - 1][X].Length)
                {
                    //Delta = this.Errors[this.Errors.Count - 1][X] * this.Activations[this.Activations.Count - 2][Y];
                    Delta = this.Errors[this.Errors.Length - 1][X] * this.Activations[this.Activations.Length - 2][Y];
                    if(double.IsNaN(Delta))
                    {
                        break;
                    }

                    if(OutputNormalizationMethod == 2)
                    {
                        //Delta *= SoftmaxDerivatives[X];
                    }

                    switch (OptimizerID)
                    {
                        case 0:
                            //this.PrevWeights[this.Errors.Count - 1][X][Y] += Delta;
                            //this.Weights[this.Weights.Count - 1][X][Y] = this.Weights[this.Weights.Count - 1][X][Y] - (SGDDelta + (0 * this.PrevWeights[this.Errors.Count - 1][X][Y]));
                            break;

                        case 1:
                            TempVal = (this.RMSPropConst * this.PrevWeights[this.PrevWeights.Length - 1][X][Y]) + ((Math.Pow(Delta, 2) * (1 - this.RMSPropConst)));
                            
                            if(TempVal < 0)
                            {
                                break;
                            }
                            
                            this.PrevWeights[this.PrevWeights.Length - 1][X][Y] = TempVal;
                            RMSPropDelta = this.LearningRate / Math.Sqrt(TempVal + 0.000000000000000000001) * Delta;
                            Delta = RMSPropDelta;

                            //this.Weights[this.Weights.Count - 1][X][Y] = this.Weights[this.Weights.Count - 1][X][Y] - RMSPropDelta;
                            break;

                        case 2:
                            this.PrevWeightsM[this.Errors.Length - 1][X][Y] = (this.B1 * this.PrevWeightsM[this.Errors.Length - 1][X][Y] + (1.0f - this.B1) * Delta);
                            this.PrevWeightsV[this.Errors.Length - 1][X][Y] = (this.B2 * this.PrevWeightsV[this.Errors.Length - 1][X][Y] + (1.0f - this.B2) * Math.Pow(Delta, 2));


                            if((this.B2 * this.PrevWeightsV[this.Errors.Length - 1][X][Y] + (1.0f - this.B2) * Math.Pow(Delta, 2)) < 0)
                            {
                                break;
                            }

                            ADAMDelta = (this.PrevWeightsM[this.Errors.Length - 1][X][Y] / (1.0f - this.B1)) / Math.Sqrt(((this.PrevWeightsV[this.Errors.Length - 1][X][Y] + 0.000000000000000000001) / (1.0f-this.B2)));
                            //this.Weights[this.Weights.Count - 1][X][Y] = this.Weights[this.Weights.Count - 1][X][Y] - this.LearningRate * ADAMDelta;
                            Delta = ADAMDelta;
                            break;
                    }

                    if(double.IsNaN(Delta))
                    {
                        break;
                    }

                    if(TrainWeights)
                    {
                        this.WeightDeltas[this.Errors.Length - 1][X][Y] += Delta;
                        this.PrevWeights[this.PrevWeights.Length - 1][X][Y] += Delta;
                    }
                    

                    Y++;
                }

                X++;
            }

            if(OnlyError == false)
            {
                //this.NormalizeWeights(this.Activations.Count - 1);
            }
            

            X = this.Activations.Length - 2;

            while (X >= 0)
            {
                Y = 0;
                while (Y < this.Activations[X].Length)
                {
                    Delta = 0;
                    Z = 0;

                    while (Z < this.Activations[X + 1].Length)
                    {
                        Delta += (this.Errors[X + 1][Z] * this.Weights[X + 1][Z][Y]);

                        Z++;
                    }

                    //Delta /= Z;

                    if (double.IsInfinity(Delta))
                    {
                        break;
                    }

                    this.Errors[X][Y] = Delta * this.ActivationFunctionDerivative(this.NetInputs[X][Y], this.ActivationFunctions[X]);
                    
                    Y++;
                }

                //this.Errors[X] = this.NormalizeDataSet(this.Errors[X], 4);

                Y = 0;
                while (Y < this.Activations[X].Length)
                {

                    if (X > 0)
                    {
                        Z = 0;
                        while (Z < this.Weights[X][Y].Length)
                        {
                            Delta = this.Errors[X][Y] * this.Activations[(X - 1)][Z];
                            //Delta = this.Errors[X][Y];

                            if (TrainWeights)
                            {                                

                                switch(OptimizerID)
                                {
                                    case 0:
                                        
                                        //this.PrevWeights[X][Y][Z] += Delta;
                                        break;

                                    case 1:
                                        TempVal = (this.RMSPropConst * this.PrevWeights[X][Y][Z]) + (Math.Pow(Delta, 2) * (1 - this.RMSPropConst)); ;
                                        this.PrevWeights[X][Y][Z] = TempVal;
                                        RMSPropDelta = this.LearningRate / Math.Sqrt(TempVal + 0.000000000000000000001) * Delta;
                                        Delta = RMSPropDelta;
                                        break;

                                    case 2:
                                        this.PrevWeightsM[X][Y][Z] = (this.B1 * this.PrevWeightsM[X][Y][Z] + (1.0f - this.B1) * Delta);
                                        this.PrevWeightsV[X][Y][Z] = (this.B2 * this.PrevWeightsV[X][Y][Z] + (1.0f - this.B2) * Math.Pow(Delta, 2));
                                        ADAMDelta = (this.PrevWeightsM[X][Y][Z] / (1.0f - this.B1)) / Math.Sqrt(((this.PrevWeightsV[X][Y][Z] + 0.000000000000000000001) / (1.0f - this.B2)));
                                        //this.Weights[X][Y][Z] = this.Weights[X][Y][Z] - this.LearningRate * ADAMDelta;
                                        Delta = ADAMDelta;
                                        break;
                                }

                            }

                            if(TrainWeights)
                            {
                                this.WeightDeltas[X][Y][Z] += Delta;
                                this.PrevWeights[X][Y][Z] += Delta;
                            }


                            Z++;
                        }
                    }

                    Y++;
                }

                X--;
            }

            
            //this.Weights = NewWeights;

        }

        public void ApplyGradients(int BatchSize)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;

            while(X < this.Weights.Length)
            {
                Y = 0;
                while(Y < this.Weights[X].Length)
                {
                    Z = 0;
                    while(Z < this.Weights[X][Y].Length)
                    {
                        this.Weights[X][Y][Z] -= ((this.WeightDeltas[X][Y][Z] / BatchSize) * this.LearningRate);

                        if(double.IsNaN(this.Weights[X][Y][Z]))
                        {
                            break;
                        }
                        this.WeightDeltas[X][Y][Z] = 0;

                        Z++;
                    }

                    Y++;
                }

                X++;
            }

            //ResetStoredAdamValues();

        }


        public double[][] SoftmaxDataSet(double[][] Inputs)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            double TempVal = 0;
            double[][] RetVal;
            List<double> TempList = new List<double>();

            //while(X < Inputs.Count)
            //{
            //    Y = 0;
            //    while(Y < Inputs[X].Count)
            //    {
            //        TempVal += Math.Exp(Inputs[X][Y]);
            //        Inputs[X][Y] = this.ActivationFunction(Inputs[X][Y], 1);

            //        Y++;
            //    }

            //    X++;
            //}

            X = 0;
            while (X < Inputs.Length)
            {
                TempList = new List<double>();
                Y = 0;
                while (Y < Inputs[X].Length)
                {
                    TempList.Add((Math.Exp(Inputs[X][Y]) / TempVal) + 0.040);

                    Y++;
                }

                //RetVal.Add(TempList);

                X++;
            }

            return Inputs;
        }



        public double CalculateStandardDeviation(List<List<double>> Inputs, double Mean = 0.0f)
        {
            double Variance = 0;
            int X = 0;
            int Y = 0;
            int Z = 0;

            if (Mean == 0)
            {
                Y = 0;
                while (Y < Inputs.Count)
                {
                    Z = 0;
                    while (Z < Inputs[Y].Count)
                    {
                        Mean += Inputs[Y][Z];

                        Z++;
                    }

                    Y++;
                }


                Mean /= (Inputs.Count * (Inputs[0].Count ));
            }

            Y = 0;
            while (Y < Inputs.Count)
            {
                Z = 0;
                while (Z < Inputs[Y].Count)
                {
                    Variance += Math.Pow(Inputs[Y][Z] - Mean, 2);

                    Z++;
                }

                Y++;
            }

            Variance /= (Inputs.Count * (Inputs[0].Count));

            return Math.Sqrt(Variance);
        }

        public double MatrixMultiply(double[] List1, double[] List2)
        {
            int X = 0;
            int Y = 0;
            double RetVal = 0;

            while(X < List1.Length)
            {
                Y = 0;
                while(Y < List2.Length)
                {
                    RetVal += (List1[X] * List2[Y]);

                    Y++;
                }

                X++;
            }

            return RetVal;
        }

        public List<double> TransposeActivations(List<double> Inputs)
        {
            List<List<double>> RetVal = new List<List<double>>();
            List<double> SubRetVal = new List<double>();
            int X = Inputs.Count - 1;

            while(X >= 0)
            {
                SubRetVal.Add(Inputs[X]);

                X--;
            }

            return SubRetVal;
        }


        public void NormalizeWeights(int LayerID)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            double Mean = 0;
            double Variance = 0;
            double StdDev = 0;
            double MaxVal = this.Weights[LayerID][0][0];
            List<double> DataList = new List<double>();
            List<double> TempList = new List<double>();
            List<List<double>> TempList2 = new List<List<double>>();
            int ItemNumber = 0;

            //Get Mean
            X = 0;
            while (X < this.Weights[LayerID].Length)
            {
                Y = 0;
                while (Y < this.Weights[LayerID][X].Length)
                {
                    if (Math.Abs(this.Weights[LayerID][X][Y]) > Math.Abs(MaxVal))
                    {
                        MaxVal = this.Weights[LayerID][X][Y];
                    }
                    ItemNumber++;

                    Y++;
                }

                X++;
            }

            Mean /= ItemNumber;

            //Get Std Dev
            ItemNumber = 0;
            X = 0;
            while (X < this.Weights[LayerID].Length)
            {
                Y = 0;
                while (Y < this.Weights[LayerID][X].Length)
                {
                    Variance += Math.Pow(this.Weights[LayerID][X][Y] - Mean, 2);
                    ItemNumber++;

                    Y++;
                }

                X++;
            }

            Variance /= ItemNumber;
            StdDev = Math.Sqrt(Variance);

            //Apply Z Score
            ItemNumber = 0;
            X = 0;
            while (X < this.Weights[LayerID].Length)
            {
                Y = 0;
                while (Y < this.Weights[LayerID][X].Length)
                {
                    this.Weights[LayerID][X][Y] = (this.Weights[LayerID][X][Y] / MaxVal);
                    ItemNumber++;

                    Y++;
                }

                X++;
            }
        }


        public double ZScore(List<double> Inputs, double SamplePoint, double Mean = 0.0f)
        {
            int X = 0;

            if (Mean == 0)
            {
                while (X < Inputs.Count)
                {
                    Mean += Inputs[X];

                    X++;
                }

                Mean /= Inputs.Count;
            }

            return (SamplePoint - Mean) / CalculateStandardDeviation(Inputs);
        }

        public void ExportNetwork(string FilePath)
        {
            int X = 0;
            int Y = 0;
            int Z = 0;
            StringBuilder StrBld = new StringBuilder();

            
        }


        public double CalculateStandardDeviation(List<double> Inputs, double Mean = 0.0f)
        {
            double Variance = 0;
            int X = 0;

            if (Mean == 0)
            {
                while (X < Inputs.Count)
                {
                    Mean += Inputs[X];

                    X++;
                }

                Mean /= Inputs.Count;
            }

            X = 0;
            while (X < Inputs.Count)
            {
                Variance += Math.Pow(Inputs[X] - Mean, 2);

                X++;
            }

            Variance /= Inputs.Count;

            return Math.Sqrt(Variance);
        }

        public double CalculateStandardDeviation(double[] Inputs, double Mean = 0.0f)
        {
            double Variance = 0;
            int X = 0;

            if (Mean == 0)
            {
                while (X < Inputs.GetUpperBound(0))
                {
                    Mean += Inputs[X];

                    X++;
                }

                Mean /= Inputs.GetUpperBound(0);
            }

            X = 0;
            while (X < Inputs.GetUpperBound(0))
            {
                Variance += Math.Pow(Inputs[X] - Mean, 2);

                X++;
            }

            Variance /= Inputs.GetUpperBound(0);

            return Math.Sqrt(Variance);
        }

        public List<double> NormalizeDataSet(List<double> Inputs, int NormalizationMethodID)
        {
            int X = 0;
            int Y = 0;
            double TempVal = 0;
            List<double> TempList = new List<double>();
            int MinibatchSize = 25;
            double StdDev = 0;
            List<double> Outputs = new List<double>();
            double MinVal = 0;
            double MaxVal = 0;
            double Mean = 0;

            if(Inputs.Count == 1)
            {
                return Inputs;
            }

            switch (NormalizationMethodID)
            {
                //TanH
                case 0:
                    while (X < Inputs.Count)
                    {
                        Inputs[X] = Math.Tanh(Inputs[X]);

                        X++;
                    }

                    break;
                //Sigmoid
                case 1:
                    while (X < Inputs.Count)
                    {
                        TempVal = Math.Exp(Inputs[X]);
                        Inputs[X] = TempVal / (TempVal + 1);

                        X++;
                    }

                    break;
                //Softmax
                case 2:
                    while (X < Inputs.Count)
                    {
                        TempVal += Math.Exp(Inputs[X]);

                        X++;
                    }

                    X = 0;

                    while (X < Inputs.Count)
                    {
                        Inputs[X] = Math.Exp(Inputs[X]) / TempVal;

                        X++;
                    }

                    break;
                //Min Max
                case 3:
                    MinVal = Inputs[0];
                    MaxVal = Inputs[0];
                    while (X < Inputs.Count)
                    {
                        if (Inputs[X] > MaxVal)
                        {
                            MaxVal = Inputs[X];
                        }

                        if (Inputs[X] < MinVal)
                        {
                            MinVal = Inputs[X];
                        }

                        X++;
                    }

                    X = 0;

                    while (X < Inputs.Count)
                    {
                        Inputs[X] = (Inputs[X] - MinVal) / (MaxVal - MinVal) ;

                        X++;
                    }

                    break;
                //Z-Score
                case 4:
                    X = 0;
                    Mean = 0;
                    TempList = new List<double>();
                    while (X < Inputs.Count)
                    {
                        if (Y + X >= Inputs.Count)
                        {
                            break;
                        }
                        //TempList.Add((Inputs[Y + X]));
                        Mean += (Inputs[Y + X]);

                        X++;
                    }

                    Mean /= Inputs.Count;
                    StdDev = CalculateStandardDeviation(Inputs, Mean);



                    X = 0;
                    while (X < Inputs.Count)
                    {
                        if (StdDev == 0)
                        {
                            Inputs[X] = (Inputs[X]);
                        }
                        else
                        {
                            Inputs[X] = ((Inputs[X] - Mean) / StdDev);
                        }

                        X++;
                    }

                    break;
                //Avg
                case 5:
                    X = 0;
                    while(X < Inputs.Count)
                    {
                        Inputs[X] /= Inputs.Count;

                        X++;
                    }

                    break;
            }

            return Inputs;
        }

        public double ActivationFunction(double Input, int ActivationFunctionID)
        {
            double TempVal = 0.0f;
            int X = 0;

            switch (ActivationFunctionID)
            {
                //TanH
                case 0:
                    TempVal = Math.Tanh(Input);

                    break;
                //Sigmoid
                case 1:
                    TempVal = 1 / (1 + Math.Pow(Math.E, -1 * Input));

                    break;
                //ELU
                case 2:
                    if (Input > 0)
                    {
                        TempVal = Input;
                    }
                    else
                    {
                        TempVal = (Math.Exp(Input) - 1.0);
                    }

                    break;
                //ReLU
                case 3:
                    if (Input > 0)
                    {
                        TempVal = Input;
                    }
                    else
                    {
                        TempVal = this.ReLUConst * Input;
                    }


                    //TempVal = Math.Max(0, Input);

                    break;
                //ELU
                case 4:
                        if (Input > 0)
                        {
                            TempVal =  Input;
                        }
                        else
                        {
                            TempVal = (Math.Pow(Math.E, Input) - 1);
                        }
                        
                        if(double.IsNaN(TempVal))
                        {
                            break;
                        }
                    break;
                //Swish
                case 5:
                    TempVal = Input * this.ActivationFunction(Input, 1);
                    break;
                case 9:
                    TempVal = Input;
                    break;
            }

            if (double.IsNaN(TempVal) || double.IsInfinity(TempVal))
            {
                Debug.Print("WARNING: NaN activation detected in network!");
            }

            return TempVal;
        }

        public double ActivationFunctionDerivative(double Input, int ActivationFunctionID)
        {
            double TempVal = 0.0f;

            switch (ActivationFunctionID)
            {
                //TanH
                case 0:
                    TempVal = Math.Tanh(Input);
                    TempVal = (1 - (TempVal * TempVal));

                    break;
                //Sigmoid
                case 1:
                    TempVal = this.ActivationFunction(Input, 1);
                    TempVal = TempVal * (1 - TempVal);

                    break;
                //ELU
                case 2:
                    if (Input > 0)
                    {
                        TempVal = 1;
                    }
                    else
                    {
                        TempVal = Math.Exp(Input);
                    }

                    break;

                case 3:
                    if (Input > 0)
                    {
                        TempVal = 1;
                    }
                    else
                    {
                        //TempVal = 0;
                        TempVal = this.ReLUConst;
                    }

                    break;

                case 4:

                    if(Input > 0)
                    {
                        TempVal = 1;
                    }
                    else
                    {
                        TempVal =Math.Pow(Math.E, Input);
                    }

                    break;
                
                case 5:
                    TempVal = this.ActivationFunction(Input,1) * this.ActivationFunction(Input, 5) * (1 - this.ActivationFunction(Input, 1));
                    break;
                case 9:
                    TempVal = Input;
                    break;
            }

            return TempVal;
        }
    }
}

